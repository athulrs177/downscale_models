{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69462c4e-76ba-47a6-a78f-4ff8b63e5aea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 11:10:22.516006: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-19 11:10:22.516048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-19 11:10:22.517078: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-19 11:10:22.523116: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-19 11:10:23.612075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Conv2DTranspose, MaxPool2D, Flatten, Conv2D, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, UpSampling2D, concatenate, Activation\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Input\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, Concatenate, LeakyReLU, Add\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import cm \n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import properscoring as ps\n",
    "\n",
    "# scaler = MaxAbsScaler()\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# tf.random.set_seed(42)  # to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a063a2-6f1c-4924-8242-425a88cfb819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137f9c7f-5d41-4a53-9db0-a4a9aa56a29e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 11:10:27.875580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79086 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2024-08-19 11:10:27.877155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79086 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:44:00.0, compute capability: 8.0\n",
      "2024-08-19 11:10:27.878572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79086 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:84:00.0, compute capability: 8.0\n",
      "2024-08-19 11:10:27.880046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79086 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c4:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Get the list of available physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Set memory growth for each GPU\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Create MirroredStrategy\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d876839-26e3-482c-a342-5824d9f0c4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diri = '/work/bb0983/athul_satheesh/e_obs_precip/'\n",
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/figures/'\n",
    "\n",
    "coarse_raw = 'rr_ens_mean_1.0deg_reg_v29.0e.nc'\n",
    "fine_raw = 'rr_ens_mean_0.1deg_reg_v29.0e.nc'\n",
    "\n",
    "lati = 43#40\n",
    "latf = 59#60\n",
    "\n",
    "loni = -6#-10\n",
    "lonf = 15#30\n",
    "\n",
    "strt = '1950-01-01'\n",
    "last = '2023-12-31'\n",
    "\n",
    "coarse_data = xr.open_dataset(diri+coarse_raw).rr.transpose('time','lat','lon').sel(time=slice(strt, last), \n",
    "                                                                                    lat=slice(lati, latf), \n",
    "                                                                                    lon=slice(loni, lonf)\n",
    "                                                                                   )\n",
    "fine_data = xr.open_dataset(diri+fine_raw).rr.transpose('time','latitude','longitude').sel(time=slice(strt, last), \n",
    "                                                                                           latitude=slice(lati, latf), \n",
    "                                                                                           longitude=slice(loni, lonf)\n",
    "                                                                                          )\n",
    "fine_data = fine_data.rename({'latitude':'lat', 'longitude':'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5df139-59b3-4c0f-b01f-db6c717413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_coarse = coarse_data.shape\n",
    "dims_fine = fine_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62136626-8e1a-4880-9706-1b7fbac4de4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27028, 16, 21), (27028, 160, 210))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims_coarse, dims_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e96e34b-64dd-40a1-a62c-464150bfd655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_strt = strt\n",
    "train_last = '2000-12-31'\n",
    "\n",
    "test_strt = '2001-01-01'\n",
    "test_last = last\n",
    "\n",
    "coarse_data_train = coarse_data.sel(time=slice(train_strt, train_last))\n",
    "coarse_data_test = coarse_data.sel(time=slice(test_strt, test_last))\n",
    "\n",
    "fine_data_train = fine_data.sel(time=slice(train_strt, train_last))\n",
    "fine_data_test = fine_data.sel(time=slice(test_strt, test_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c02225-58ae-43f0-99e2-10aebc02f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_nan_mask = np.isnan(coarse_data_test)\n",
    "fine_nan_mask = np.isnan(fine_data_test)\n",
    "\n",
    "fill_val = -1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b631b060-a6bb-4fe6-90ac-55b42c993ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_data_train = coarse_data_train.fillna(fill_val)\n",
    "coarse_data_test = coarse_data_test.fillna(fill_val)\n",
    "\n",
    "fine_data_train = fine_data_train.fillna(fill_val)\n",
    "fine_data_test = fine_data_test.fillna(fill_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df65693-9401-4fb3-b807-624a93043b62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def ssim_loss(fake_images, real_images):\n",
    "#     \"\"\"\n",
    "#     Computes the SSIM loss between fake and real images.\n",
    "    \n",
    "#     Parameters:\n",
    "#         fake_images (tf.Tensor): Generated images.\n",
    "#         real_images (tf.Tensor): Real images.\n",
    "    \n",
    "#     Returns:\n",
    "#         tf.Tensor: SSIM loss.\n",
    "#     \"\"\"\n",
    "#     ssim_index = tf.image.ssim(fake_images, real_images, max_val=1.0)\n",
    "#     return 1 - tf.reduce_mean(ssim_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d6bde78-8809-4e7e-9594-16e802d4ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crps_loss(predictions, observed):\n",
    "    \"\"\"\n",
    "    Computes the CRPS loss for an ensemble of predictions against observed data.\n",
    "    \n",
    "    Parameters:\n",
    "        predictions (tf.Tensor): Tensor of shape (batch_size, ensemble_size, height, width, channels)\n",
    "                                 representing the ensemble of predictions.\n",
    "        observed (tf.Tensor): Tensor of shape (batch_size, height, width, channels) representing the observed data.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: The CRPS loss.\n",
    "    \"\"\"\n",
    "    # Sort the predictions to compute the empirical CDF\n",
    "    sorted_predictions = tf.sort(predictions, axis=1)\n",
    "    \n",
    "    # Reshape observed data to match the ensemble shape for broadcasting\n",
    "    observed = tf.expand_dims(observed, axis=1)\n",
    "    \n",
    "    # Calculate the empirical CDF\n",
    "    cdf = tf.cumsum(tf.ones_like(sorted_predictions) / tf.cast(tf.shape(sorted_predictions)[1], tf.float32), axis=1)\n",
    "    \n",
    "    # CRPS calculation\n",
    "    crps = tf.reduce_mean((cdf - tf.cast(sorted_predictions >= observed, tf.float32))**2, axis=1)\n",
    "    \n",
    "    return tf.reduce_mean(crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba6bc73-e0d0-4acd-b161-70eb80f6749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output, fake_images, real_images, penalty_weight=10, crps_weight=10):\n",
    "    \"\"\"\n",
    "    Generator loss function using Wasserstein loss with an added penalty term and SSIM loss.\n",
    "    \n",
    "    Parameters:\n",
    "        fake_output (tf.Tensor): Output of the discriminator when given generated images.\n",
    "        fake_images (tf.Tensor): Generated images.\n",
    "        real_images (tf.Tensor): Real images.\n",
    "        penalty_weight (float): Weight of the penalty term.\n",
    "        ssim_weight (float): Weight of the SSIM loss term.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Generator loss.\n",
    "    \"\"\"\n",
    "    # print(fake_images.shape)\n",
    "    # print(real_images.shape)\n",
    "    # print(tf.reduce_mean(fake_images, axis=-1).shape)\n",
    "    # print(tf.reshape( tf.reduce_mean(fake_images, axis=-1), real_images.shape + (1,)).shape)\n",
    "\n",
    "    \n",
    "    wasserstein_loss = -tf.reduce_mean(fake_output)\n",
    "    \n",
    "    # Penalty term for deviation from real outputs\n",
    "    # penalty = penalty_weight * tf.reduce_mean(tf.abs(fake_output - real_output))\n",
    "    penalty = penalty_weight * tf.reduce_mean(tf.abs(tf.reduce_mean(fake_images, axis=-1, keepdims=True) - real_images) )\n",
    "    \n",
    "    # CRPS loss\n",
    "    crps_loss_value = crps_loss(fake_images, real_images)\n",
    "    \n",
    "    return wasserstein_loss + penalty + crps_weight * crps_loss_value\n",
    "    # return wasserstein_loss + ssim_weight * ssim_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "604a37c3-245f-4b33-a649-89bdc7fea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    Discriminator loss function using Wasserstein loss.\n",
    "    \n",
    "    Parameters:\n",
    "        real_output (tf.Tensor): Output of the discriminator when given real images.\n",
    "        fake_output (tf.Tensor): Output of the discriminator when given generated images.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Discriminator loss.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78903fd8-d505-44ff-9b30-2a989bb62c0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def discriminator_loss(real_output, fake_output, real_images, fake_images, gradient_penalty_weight=10):\n",
    "#     \"\"\"\n",
    "#     Discriminator loss function using Wasserstein loss and gradient penalty.\n",
    "    \n",
    "#     Parameters:\n",
    "#         real_output (tf.Tensor): Output of the discriminator when given real images.\n",
    "#         fake_output (tf.Tensor): Output of the discriminator when given generated images.\n",
    "#         real_images (tf.Tensor): Real images.\n",
    "#         fake_images (tf.Tensor): Generated images.\n",
    "#         gradient_penalty_weight (float): Weight of the gradient penalty term.\n",
    "    \n",
    "#     Returns:\n",
    "#         tf.Tensor: Discriminator loss.\n",
    "#     \"\"\"\n",
    "#     wasserstein_loss = tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)\n",
    "    \n",
    "#     # Gradient penalty\n",
    "#     batch_size = real_images.shape[0]\n",
    "#     alpha = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0., maxval=1.)\n",
    "#     interpolated = alpha * real_images + (1 - alpha) * fake_images\n",
    "    \n",
    "#     with tf.GradientTape() as tape:\n",
    "#         tape.watch(interpolated)\n",
    "#         interpolated_output = discriminator(interpolated)\n",
    "    \n",
    "#     gradients = tape.gradient(interpolated_output, [interpolated])[0]\n",
    "#     gradients_norm = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
    "#     gradient_penalty = gradient_penalty_weight * tf.reduce_mean((gradients_norm - 1.0) ** 2)\n",
    "    \n",
    "#     return wasserstein_loss + gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8dfff4f-9339-4189-93bc-156b79d5514d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Weight clipping\n",
    "def clip_weights(model, clip_value):\n",
    "    \"\"\"\n",
    "    Clips the weights of the model to be within the range [-clip_value, clip_value].\n",
    "    \n",
    "    Parameters:\n",
    "        model (tf.keras.Model): The model whose weights will be clipped.\n",
    "        clip_value (float): The value to clip the weights to.\n",
    "    \"\"\"\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            kernel = layer.kernel\n",
    "            clipped_kernel = tf.clip_by_value(kernel, -clip_value, clip_value)\n",
    "            layer.kernel.assign(clipped_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "607b5e27-ae75-41c1-bdd9-4c1909a8a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a custom dropout layer that is active also during prediction and use this in the model instead of the default Dropout.\n",
    "# Alternatively you can also set \"training=True\" in the Dropout layer\n",
    "@register_keras_serializable()\n",
    "class CustomDropout(Dropout):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(rate, **kwargs)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        return super().call(inputs, training=True)  # Always active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87d1e80a-5fd7-4262-8fcc-e4b28f96fe35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size, name, dilation_rate, strides=(1,1), use_batch_norm=True, use_dropout=True):\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, dilation_rate=dilation_rate, strides=strides, padding='same', \n",
    "               kernel_initializer=he_normal(), name=name+'_conv')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=name+'_lrelu')(x)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization(name=name+'_bn')(x)\n",
    "    if use_dropout:\n",
    "        # x = Dropout(0.25, name=name+'_dropout')(x, training=True)\n",
    "        x = CustomDropout(0.25, name=name+'_dropout')(x)\n",
    "    return x\n",
    "\n",
    "def deconv_block(x, filters, kernel_size, strides, name, dilation_rate, use_batch_norm=True, use_dropout=True):\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=kernel_size, dilation_rate=dilation_rate, strides=strides, \n",
    "                        padding='same', kernel_initializer=he_normal(), name=name+'_deconv')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=name+'_lrelu')(x)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization(name=name+'_bn')(x)\n",
    "    if use_dropout:\n",
    "        x = CustomDropout(0.25, name=name+'_dropout')(x)\n",
    "    return x\n",
    "\n",
    "# def upsampling_block(inputs, filters, kernel_size, upsample_factor, name, dilation_rate, strides, use_batch_norm=True, use_dropout=True):\n",
    "#     x = UpSampling2D(size=upsample_factor, name=name+'_upsample')(inputs)\n",
    "#     x = Conv2D(filters, kernel_size, dilation_rate=dilation_rate, padding='same', strides=strides,\n",
    "#                kernel_initializer=he_normal(), name=name+'_conv')(x)\n",
    "#     x = LeakyReLU(alpha=0.2, name=name+'_lrelu')(x)\n",
    "#     if use_batch_norm:\n",
    "#         x = BatchNormalization(name=name+'_bn')(x)\n",
    "#     if use_dropout:\n",
    "#         x = CustomDropout(0.25, name=name+'_dropout')(x)\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fad772e-73f3-4bb8-87c2-5243d70ea2e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def build_generator(input_shape):\n",
    "#     inputs = Input(shape=input_shape, name='generator_input')\n",
    "\n",
    "#     # Downsampling\n",
    "#     downsample_3 = conv_block(inputs, 512, (3, 3), 'downsample_3', (1,1))\n",
    "#     downsample_2 = conv_block(downsample_3, 256, (3, 3), 'downsample_2', (1,1))\n",
    "#     downsample_1 = conv_block(downsample_2, 128, (3, 3), 'downsample_1', (1,1))\n",
    "#     downsample_0 = conv_block(downsample_1, 64, (3, 3), 'downsample_0', (1,1))\n",
    "\n",
    "#     # Bottleneck\n",
    "#     bottleneck_0 = conv_block(downsample_0, 32, (3, 3), 'bottleneck_0', (1,1))\n",
    "#     bottleneck_00 = conv_block(bottleneck_0, 32, (3, 3), 'bottleneck_00', (1,1))\n",
    "\n",
    "#     # Upsampling\n",
    "#     upsample_0 = upsampling_block(bottleneck_00, 64, (3, 3), (1,1), 'upsample_0', (1,1), (1,1))\n",
    "#     upsample_1 = upsampling_block(upsample_0, 128, (3, 3), (1,1), 'upsample_1', (1,1), (1,1))\n",
    "#     upsample_2 = upsampling_block(upsample_1, 256, (3, 3), (2,2), 'upsample_2', (1,1), (1,1))\n",
    "#     upsample_3 = upsampling_block(upsample_2, 512, (6, 6), (5,5), 'upsample_3', (1,1), (1,1))\n",
    "    \n",
    "#     # Final Upsample to required shape\n",
    "#     outputs = Conv2D(filters=1, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "#                               strides=(1, 1), activation='relu', name='final_upsample_conv')(upsample_3)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5ed50c6-6759-4437-a882-e1c43c45b03d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def build_generator(input_shape):\n",
    "#     inputs = Input(shape=input_shape, name='generator_input')\n",
    "\n",
    "#     # Convolutions\n",
    "#     conv_3 = conv_block(inputs, 512, (3, 3), 'conv_3', (1,1))\n",
    "#     conv_2 = conv_block(conv_3, 256, (3, 3), 'conv_2', (1,1))\n",
    "#     conv_1 = conv_block(conv_2, 128, (3, 3), 'conv_1', (1,1))\n",
    "#     conv_0 = conv_block(conv_1, 64, (3, 3), 'conv_0', (1,1))\n",
    "    \n",
    "#     # Bottleneck\n",
    "#     bottleneck_0 = conv_block(conv_0, 32, (3, 3), 'bottleneck_0', (1,1))\n",
    "#     bottleneck_00 = conv_block(bottleneck_0, 32, (3, 3), 'bottleneck_00', (1,1))\n",
    "    \n",
    "#     # Upsampling with skip connections\n",
    "#     deconv_0 = deconv_block(bottleneck_00, 64, (3, 3), (1,1), 'deconv_0', (1,1))\n",
    "#     deconv_1 = deconv_block(deconv_0, 128, (3, 3), (1,1), 'deconv_1', (1,1))\n",
    "#     deconv_2 = deconv_block(deconv_1, 256, (3, 3), (2,2), 'deconv_2', (1,1))\n",
    "#     deconv_3 = deconv_block(deconv_2, 512, (6, 6), (5,5), 'deconv_3', (1,1))\n",
    "    \n",
    "#     # Final Upsample to required shape\n",
    "#     outputs = Conv2D(filters=1, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "#                               strides=(1, 1), activation='relu', name='final_conv')(deconv_3)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eb51275-c6f1-459a-829a-81fa692fa95b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator(input_shape):\n",
    "    inputs = Input(shape=input_shape, name='generator_input')\n",
    "\n",
    "    # Convolutions\n",
    "    conv_4 = conv_block(inputs, 16, (3, 3), 'conv_4', (1,1))\n",
    "    conv_3 = conv_block(conv_4, 32, (3, 3), 'conv_3', (1,1))\n",
    "    conv_2 = conv_block(conv_3, 64, (3, 3), 'conv_2', (1,1))\n",
    "    conv_1 = conv_block(conv_2, 128, (3, 3), 'conv_1', (1,1))\n",
    "    conv_0 = conv_block(conv_1, 256, (3, 3), 'conv_0', (1,1))\n",
    "    conv_00 = conv_block(conv_0, 512, (3, 3), 'conv_00', (1,1))\n",
    "    \n",
    "    # Upsampling\n",
    "    deconv_00 = deconv_block(conv_00, 512, (3, 3), (1,1), 'deconv_00', (1,1))\n",
    "    deconv_0 = deconv_block(deconv_00, 256, (3, 3), (1,1), 'deconv_0', (1,1))\n",
    "    deconv_1 = deconv_block(deconv_0, 128, (3, 3), (1,1), 'deconv_1', (1,1))\n",
    "    deconv_2 = deconv_block(deconv_1, 64, (3, 3), (1,1), 'deconv_2', (1,1))\n",
    "    # deconv_3 = deconv_block(deconv_2, 32, (3, 3), (2,2), 'deconv_3', (1,1))\n",
    "    deconv_3 = deconv_block(deconv_2, 32, (3, 3), (1,1), 'deconv_3', (1,1))\n",
    "    deconv_4 = deconv_block(deconv_3, 16, (6, 6), (5,5), 'deconv_4', (1,1))\n",
    "    \n",
    "    # Final Upsample to required shape\n",
    "    # outputs = Conv2D(filters=50, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "    #                           strides=(1, 1), activation='relu', name='final_conv')(deconv_4)\n",
    "    outputs = Conv2DTranspose(filters=50, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "                              strides=(2, 2), activation='relu', name='final_deconv')(deconv_4)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f234c3b9-ef2c-4bac-bcd0-facbca2feda8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def build_discriminator(input_shape):\n",
    "#     input_layer = Input(shape=input_shape, name='discriminator_input')\n",
    "\n",
    "#     x = conv_block(input_layer, filters=16, kernel_size=(3, 3), name='conv1', dilation_rate=(1,1), strides=(2,2), use_dropout=False, use_batch_norm=False)\n",
    "#     x = conv_block(x, filters=32, kernel_size=(3, 3), name='conv2', dilation_rate=(1,1), strides=(1,1), use_dropout=False, use_batch_norm=False)\n",
    "#     x = conv_block(x, filters=64, kernel_size=(3, 3), name='conv3', dilation_rate=(1,1), strides=(1,1), use_dropout=False, use_batch_norm=False)\n",
    "#     x = conv_block(x, filters=128, kernel_size=(3, 3), name='conv4', dilation_rate=(1,1), strides=(1,1), use_dropout=False, use_batch_norm=False)\n",
    "#     x = conv_block(x, filters=256, kernel_size=(3, 3), name='conv5', dilation_rate=(1,1), strides=(1,1), use_dropout=False, use_batch_norm=False)\n",
    "#     x = conv_block(x, filters=512, kernel_size=(3, 3), name='conv6', dilation_rate=(1,1), strides=(1,1), use_dropout=False, use_batch_norm=False)\n",
    "        \n",
    "#     x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "#     x = Dropout(0.25)(x)\n",
    "#     x = Flatten()(x)\n",
    "#     output_layer = Dense(1, activation='linear')(x)\n",
    "#     # output_layer = Conv2D(filters=1, kernel_size=(3, 3), padding='same', activation='linear', name='final_conv')(x)\n",
    "    \n",
    "#     model = Model(inputs=input_layer, outputs=output_layer, name='wGAN_discriminator')\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ce017a-f304-4f87-89a0-5a89e956babd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape):\n",
    "    input_layer = Input(shape=input_shape, name='discriminator_input')\n",
    "\n",
    "    x = conv_block(input_layer, filters=16, kernel_size=(3, 3), name='conv1', dilation_rate=(1,1), strides=(2,2), use_dropout=False)\n",
    "    # x = conv_block(x, filters=32, kernel_size=(3, 3), name='conv2', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "    x = conv_block(x, filters=64, kernel_size=(3, 3), name='conv3', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "    # x = conv_block(x, filters=128, kernel_size=(3, 3), name='conv4', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "    x = conv_block(x, filters=256, kernel_size=(3, 3), name='conv5', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "    # x = conv_block(x, filters=512, kernel_size=(3, 3), name='conv6', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "        \n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    # output_layer = Dense(1, activation='linear')(x)\n",
    "    output_layer = Conv2D(filters=1, kernel_size=(3, 3), padding='same', activation='linear', name='final_conv')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='wGAN_discriminator')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b4a52d5-1aef-4f4f-b49a-e04f42afe606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "input_shape  = dims_coarse[1:] + (1,)\n",
    "output_shape = dims_fine[1:] + (1,)\n",
    "\n",
    "# lr = 0.5e-5\n",
    "gen_lr = 2e-4\n",
    "dis_lr = 2e-4\n",
    "clip_value = 1e-3\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    # gen_optimizer = RMSprop(learning_rate=lr, momentum=0.5)\n",
    "    # dis_optimizer = RMSprop(learning_rate=lr, momentum=0.5)\n",
    "    gen_optimizer = Adam(learning_rate=gen_lr)\n",
    "    dis_optimizer = Adam(learning_rate=dis_lr)\n",
    "    \n",
    "    gen = build_generator(input_shape)\n",
    "    dis = build_discriminator(output_shape)\n",
    "\n",
    "    gen.compile(optimizer=gen_optimizer,)\n",
    "    dis.compile(optimizer=dis_optimizer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4838ac4-2d1f-46a0-9bf3-acc9bcee8ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " generator_input (InputLaye  [(None, 16, 21, 1)]       0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " conv_4_conv (Conv2D)        (None, 16, 21, 16)        160       \n",
      "                                                                 \n",
      " conv_4_lrelu (LeakyReLU)    (None, 16, 21, 16)        0         \n",
      "                                                                 \n",
      " conv_4_bn (BatchNormalizat  (None, 16, 21, 16)        64        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_4_dropout (CustomDrop  (None, 16, 21, 16)        0         \n",
      " out)                                                            \n",
      "                                                                 \n",
      " conv_3_conv (Conv2D)        (None, 16, 21, 32)        4640      \n",
      "                                                                 \n",
      " conv_3_lrelu (LeakyReLU)    (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " conv_3_bn (BatchNormalizat  (None, 16, 21, 32)        128       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_3_dropout (CustomDrop  (None, 16, 21, 32)        0         \n",
      " out)                                                            \n",
      "                                                                 \n",
      " conv_2_conv (Conv2D)        (None, 16, 21, 64)        18496     \n",
      "                                                                 \n",
      " conv_2_lrelu (LeakyReLU)    (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " conv_2_bn (BatchNormalizat  (None, 16, 21, 64)        256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_2_dropout (CustomDrop  (None, 16, 21, 64)        0         \n",
      " out)                                                            \n",
      "                                                                 \n",
      " conv_1_conv (Conv2D)        (None, 16, 21, 128)       73856     \n",
      "                                                                 \n",
      " conv_1_lrelu (LeakyReLU)    (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " conv_1_bn (BatchNormalizat  (None, 16, 21, 128)       512       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_1_dropout (CustomDrop  (None, 16, 21, 128)       0         \n",
      " out)                                                            \n",
      "                                                                 \n",
      " conv_0_conv (Conv2D)        (None, 16, 21, 256)       295168    \n",
      "                                                                 \n",
      " conv_0_lrelu (LeakyReLU)    (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " conv_0_bn (BatchNormalizat  (None, 16, 21, 256)       1024      \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_0_dropout (CustomDrop  (None, 16, 21, 256)       0         \n",
      " out)                                                            \n",
      "                                                                 \n",
      " conv_00_conv (Conv2D)       (None, 16, 21, 512)       1180160   \n",
      "                                                                 \n",
      " conv_00_lrelu (LeakyReLU)   (None, 16, 21, 512)       0         \n",
      "                                                                 \n",
      " conv_00_bn (BatchNormaliza  (None, 16, 21, 512)       2048      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv_00_dropout (CustomDro  (None, 16, 21, 512)       0         \n",
      " pout)                                                           \n",
      "                                                                 \n",
      " deconv_00_deconv (Conv2DTr  (None, 16, 21, 512)       2359808   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " deconv_00_lrelu (LeakyReLU  (None, 16, 21, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " deconv_00_bn (BatchNormali  (None, 16, 21, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " deconv_00_dropout (CustomD  (None, 16, 21, 512)       0         \n",
      " ropout)                                                         \n",
      "                                                                 \n",
      " deconv_0_deconv (Conv2DTra  (None, 16, 21, 256)       1179904   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_0_lrelu (LeakyReLU)  (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " deconv_0_bn (BatchNormaliz  (None, 16, 21, 256)       1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_0_dropout (CustomDr  (None, 16, 21, 256)       0         \n",
      " opout)                                                          \n",
      "                                                                 \n",
      " deconv_1_deconv (Conv2DTra  (None, 16, 21, 128)       295040    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_1_lrelu (LeakyReLU)  (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " deconv_1_bn (BatchNormaliz  (None, 16, 21, 128)       512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_1_dropout (CustomDr  (None, 16, 21, 128)       0         \n",
      " opout)                                                          \n",
      "                                                                 \n",
      " deconv_2_deconv (Conv2DTra  (None, 16, 21, 64)        73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_2_lrelu (LeakyReLU)  (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " deconv_2_bn (BatchNormaliz  (None, 16, 21, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_2_dropout (CustomDr  (None, 16, 21, 64)        0         \n",
      " opout)                                                          \n",
      "                                                                 \n",
      " deconv_3_deconv (Conv2DTra  (None, 16, 21, 32)        18464     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_3_lrelu (LeakyReLU)  (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " deconv_3_bn (BatchNormaliz  (None, 16, 21, 32)        128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_3_dropout (CustomDr  (None, 16, 21, 32)        0         \n",
      " opout)                                                          \n",
      "                                                                 \n",
      " deconv_4_deconv (Conv2DTra  (None, 80, 105, 16)       18448     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_4_lrelu (LeakyReLU)  (None, 80, 105, 16)       0         \n",
      "                                                                 \n",
      " deconv_4_bn (BatchNormaliz  (None, 80, 105, 16)       64        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_4_dropout (CustomDr  (None, 80, 105, 16)       0         \n",
      " opout)                                                          \n",
      "                                                                 \n",
      " final_deconv (Conv2DTransp  (None, 160, 210, 50)      7250      \n",
      " ose)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5533250 (21.11 MB)\n",
      "Trainable params: 5529218 (21.09 MB)\n",
      "Non-trainable params: 4032 (15.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a532b24-5242-48d5-b62c-df4de0b79378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wGAN_discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " discriminator_input (Input  [(None, 160, 210, 1)]     0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " conv1_conv (Conv2D)         (None, 80, 105, 16)       160       \n",
      "                                                                 \n",
      " conv1_lrelu (LeakyReLU)     (None, 80, 105, 16)       0         \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 80, 105, 16)       64        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv3_conv (Conv2D)         (None, 80, 105, 64)       9280      \n",
      "                                                                 \n",
      " conv3_lrelu (LeakyReLU)     (None, 80, 105, 64)       0         \n",
      "                                                                 \n",
      " conv3_bn (BatchNormalizati  (None, 80, 105, 64)       256       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv5_conv (Conv2D)         (None, 80, 105, 256)      147712    \n",
      "                                                                 \n",
      " conv5_lrelu (LeakyReLU)     (None, 80, 105, 256)      0         \n",
      "                                                                 \n",
      " conv5_bn (BatchNormalizati  (None, 80, 105, 256)      1024      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 40, 52, 256)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 52, 256)       0         \n",
      "                                                                 \n",
      " final_conv (Conv2D)         (None, 40, 52, 1)         2305      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160801 (628.13 KB)\n",
      "Trainable params: 160129 (625.50 KB)\n",
      "Non-trainable params: 672 (2.62 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "160299f8-d49d-4cc5-90fa-c48fc83fc019",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "def preprocess_data(data):\n",
    "    data = tf.convert_to_tensor(data.values, dtype=tf.float32)\n",
    "    return tf.reshape(data, data.shape + (1,))\n",
    "# Compute and update gradients\n",
    "def train_step(coarse_data_batch, fine_data_batch, dis, clip_value):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "        fake_data_batch = gen(coarse_data_batch, training=True)\n",
    "        real_output = dis(fine_data_batch, training=True)\n",
    "        # fake_output = dis(fake_data_batch[...,-1], training=True)\n",
    "        fake_output = dis( tf.reshape(tf.reduce_mean(fake_data_batch, axis=-1), fine_data_batch.shape + (1,)), training=True) # change to a single member instead of the mean if required\n",
    "        gen_loss = generator_loss(fake_output, fake_data_batch, fine_data_batch)\n",
    "        dis_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_gen = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "    gradients_of_dis = dis_tape.gradient(dis_loss, dis.trainable_variables)\n",
    "    \n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_gen, gen.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(gradients_of_dis, dis.trainable_variables))\n",
    "    \n",
    "    # Clip discriminator weights\n",
    "    clip_weights(dis, clip_value)\n",
    "    \n",
    "    return gen_loss, dis_loss\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(coarse_data_batch, fine_data_batch, dis, clip_value):\n",
    "    per_replica_gen_losses, per_replica_dis_losses = strategy.run(train_step, args=(coarse_data_batch, fine_data_batch, dis, clip_value))\n",
    "    mean_gen_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_gen_losses, axis=None)\n",
    "    mean_dis_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_dis_losses, axis=None)\n",
    "    return mean_gen_loss, mean_dis_loss\n",
    "\n",
    "def train_gan(gen, dis, coarse_data_train, fine_data_train, clip_value, epochs, batch_size, save_intermediate=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((preprocess_data(coarse_data_train), preprocess_data(fine_data_train)))\n",
    "    # dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).repeat(epochs)\n",
    "    dataset = dataset.shuffle(buffer_size=365*2).batch(batch_size)#.repeat(epochs)\n",
    "    distributed_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_gen_loss = 0.0\n",
    "        total_dis_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for coarse_data_batch, fine_data_batch in distributed_dataset:\n",
    "            gen_loss, dis_loss = distributed_train_step(coarse_data_batch, fine_data_batch, dis, clip_value)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_dis_loss += dis_loss\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_dis_loss = total_dis_loss / num_batches\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Generator Loss: {avg_gen_loss:.5f}, Discriminator Loss: {avg_dis_loss:.5f}\")\n",
    "\n",
    "        # Save models every 100 epochs\n",
    "        if save_intermediate:\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                gen.save(f'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/generator_prob_epoch_{epoch+1}_adam_crps.keras')\n",
    "                dis.save(f'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/discriminator_prob_epoch_{epoch+1}_adam_crps.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4dbf5d5d-484f-4c2f-b1fc-7b4a13d15d07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def preprocess_data(data):\n",
    "#     data = tf.convert_to_tensor(data.values, dtype=tf.float32)\n",
    "#     return tf.reshape(data, data.shape + (1,))\n",
    "\n",
    "# # Compute and update gradients\n",
    "# def train_discriminator_step(coarse_data_batch, fine_data_batch, dis, clip_value):\n",
    "#     with tf.GradientTape() as dis_tape:\n",
    "#         fake_data_batch = gen(coarse_data_batch, training=True)\n",
    "#         real_output = dis(fine_data_batch, training=True)\n",
    "#         fake_output = dis(fake_data_batch, training=True)\n",
    "#         dis_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "#     gradients_of_dis = dis_tape.gradient(dis_loss, dis.trainable_variables)\n",
    "#     dis_optimizer.apply_gradients(zip(gradients_of_dis, dis.trainable_variables))\n",
    "    \n",
    "#     # Clip discriminator weights\n",
    "#     clip_weights(dis, clip_value)\n",
    "    \n",
    "#     return dis_loss\n",
    "\n",
    "# def train_generator_step(coarse_data_batch, fine_data_batch, dis):\n",
    "#     with tf.GradientTape() as gen_tape:\n",
    "#         fake_data_batch = gen(coarse_data_batch, training=True)\n",
    "#         fake_output = dis(fake_data_batch, training=True)\n",
    "#         real_output = dis(fine_data_batch, training=True)\n",
    "#         gen_loss = generator_loss(fake_output, real_output, fake_data_batch, fine_data_batch)\n",
    "\n",
    "#     gradients_of_gen = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "#     gen_optimizer.apply_gradients(zip(gradients_of_gen, gen.trainable_variables))\n",
    "    \n",
    "#     return gen_loss\n",
    "\n",
    "# @tf.function\n",
    "# def distributed_discriminator_step(coarse_data_batch, fine_data_batch, dis, clip_value):\n",
    "#     per_replica_dis_losses = strategy.run(train_discriminator_step, args=(coarse_data_batch, fine_data_batch, dis, clip_value))\n",
    "#     mean_dis_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_dis_losses, axis=None)\n",
    "#     return mean_dis_loss\n",
    "\n",
    "# @tf.function\n",
    "# def distributed_generator_step(coarse_data_batch, fine_data_batch, dis):\n",
    "#     per_replica_gen_losses = strategy.run(train_generator_step, args=(coarse_data_batch, fine_data_batch, dis))\n",
    "#     mean_gen_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_gen_losses, axis=None)\n",
    "#     return mean_gen_loss\n",
    "\n",
    "# def train_gan(gen, dis, coarse_data_train, fine_data_train, clip_value, epochs, batch_size, save_intermediate=True, d_steps=5):\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((preprocess_data(coarse_data_train), preprocess_data(fine_data_train)))\n",
    "#     dataset = dataset.shuffle(buffer_size=365*2).batch(batch_size)\n",
    "#     distributed_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         total_gen_loss = 0.0\n",
    "#         total_dis_loss = 0.0\n",
    "#         num_batches = 0\n",
    "\n",
    "#         for coarse_data_batch, fine_data_batch in distributed_dataset:\n",
    "#             for _ in range(d_steps):\n",
    "#                 dis_loss = distributed_discriminator_step(coarse_data_batch, fine_data_batch, dis, clip_value)\n",
    "#                 total_dis_loss += dis_loss\n",
    "#                 num_batches += 1\n",
    "\n",
    "#             gen_loss = distributed_generator_step(coarse_data_batch, fine_data_batch, dis)\n",
    "#             total_gen_loss += gen_loss\n",
    "\n",
    "#         avg_gen_loss = total_gen_loss / num_batches\n",
    "#         avg_dis_loss = total_dis_loss / (num_batches * d_steps)\n",
    "        \n",
    "#         if (epoch + 1) % 10 == 0:\n",
    "#             print(f\"Epoch {epoch + 1}, Generator Loss: {avg_gen_loss:.5f}, Discriminator Loss: {avg_dis_loss:.5f}\")\n",
    "\n",
    "#         # Save models every 100 epochs\n",
    "#         if save_intermediate and (epoch + 1) % 50 == 0:\n",
    "#             gen.save(f'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/generator_prob_epoch_{epoch+1}.keras')\n",
    "#             dis.save(f'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/discriminator_prob_epoch_{epoch+1}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dd48624-396c-4587-af41-bbd009eb9d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 850\n",
    "batch_size = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e29b3-4acf-4a3b-87c2-9024a8313cf8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 50 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 50 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 11:11:43.515685: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inreplica_1/generator/conv_4_dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_gan(gen, dis, coarse_data_train, fine_data_train, clip_value, epochs, batch_size, save_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4468dabb-f8c7-4821-9ff1-5e665193a832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unset the random seed to generate ensembles\n",
    "tf.random.set_seed(None) \n",
    "\n",
    "downscaled_data_mem1 = gen.predict( coarse_data_test.values.reshape( coarse_data_test.shape + (1,) ) )\n",
    "downscaled_data_mem2 = gen.predict( coarse_data_test.values.reshape( coarse_data_test.shape + (1,) ) )\n",
    "downscaled_data_mem3 = gen.predict( coarse_data_test.values.reshape( coarse_data_test.shape + (1,) ) )\n",
    "downscaled_data_mem4 = gen.predict( coarse_data_test.values.reshape( coarse_data_test.shape + (1,) ) )\n",
    "downscaled_data_mem5 = gen.predict( coarse_data_test.values.reshape( coarse_data_test.shape + (1,) ) )\n",
    "downscaled_data_mem6 = gen.predict( coarse_data_test.values.reshape( coarse_data_test.shape + (1,) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0cf8a-a50d-44e7-b636-0e8536cd67b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downscaled_data_mem1.shape, downscaled_data_mem2.shape, downscaled_data_mem3.shape, downscaled_data_mem4.shape, downscaled_data_mem5.shape, downscaled_data_mem6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fd189-3b3f-4ba1-89f0-ee4fa0fc4e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downscaled_data = inverse_normalize_data(downscaled_data, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f0bed-cbf5-4571-b4ca-37537adab2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downscaled_data_mem1 = xr.DataArray(name='precipitation', data=downscaled_data_mem1.squeeze(), \n",
    "                               dims=fine_data_test.dims, coords=fine_data_test.coords, \n",
    "                               attrs=fine_data_test.attrs)\n",
    "downscaled_data_mem1 = downscaled_data_mem1.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "downscaled_data_mem2 = xr.DataArray(name='precipitation', data=downscaled_data_mem2.squeeze(), \n",
    "                               dims=fine_data_test.dims, coords=fine_data_test.coords, \n",
    "                               attrs=fine_data_test.attrs)\n",
    "downscaled_data_mem2 = downscaled_data_mem2.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "downscaled_data_mem3 = xr.DataArray(name='precipitation', data=downscaled_data_mem3.squeeze(), \n",
    "                               dims=fine_data_test.dims, coords=fine_data_test.coords, \n",
    "                               attrs=fine_data_test.attrs)\n",
    "downscaled_data_mem3 = downscaled_data_mem3.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "downscaled_data_mem4 = xr.DataArray(name='precipitation', data=downscaled_data_mem4.squeeze(), \n",
    "                               dims=fine_data_test.dims, coords=fine_data_test.coords, \n",
    "                               attrs=fine_data_test.attrs)\n",
    "downscaled_data_mem4 = downscaled_data_mem4.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "downscaled_data_mem5 = xr.DataArray(name='precipitation', data=downscaled_data_mem5.squeeze(), \n",
    "                               dims=fine_data_test.dims, coords=fine_data_test.coords, \n",
    "                               attrs=fine_data_test.attrs)\n",
    "downscaled_data_mem5 = downscaled_data_mem5.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "downscaled_data_mem6 = xr.DataArray(name='precipitation', data=downscaled_data_mem6.squeeze(), \n",
    "                               dims=fine_data_test.dims, coords=fine_data_test.coords, \n",
    "                               attrs=fine_data_test.attrs)\n",
    "downscaled_data_mem6 = downscaled_data_mem6.where(~fine_nan_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e122c-acc7-4911-ad98-52ad04e5ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscaled_data_list = [downscaled_data_mem1, downscaled_data_mem2, downscaled_data_mem3, \n",
    "                   downscaled_data_mem4, downscaled_data_mem5, downscaled_data_mem6\n",
    "                  ]\n",
    "downscaled_data = xr.concat(downscaled_data_list, dim='number')\n",
    "downscaled_data = downscaled_data.assign_coords(number=np.arange( len(downscaled_data_list)) )\n",
    "downscaled_data = downscaled_data.transpose('time', 'lat', 'lon', 'number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e4b2ec-0fcc-4708-aab5-586499f82a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af789b1c-4f8d-4bfb-8636-f0019fc72d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downscaled_data = downscaled_data.where(~fine_nan_mask, np.nan)\n",
    "fine_data_test = fine_data_test.where(~fine_nan_mask, np.nan)\n",
    "coarse_data_test = coarse_data_test.where(~coarse_nan_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e60550-1412-4666-9aef-ef1405a582a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/downscaled_data/'\n",
    "# downscaled_data.to_netcdf(diro + 'e_obs_eu_downscaled_wgan_prob.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c82756-fa6d-4a2b-8099-a0e6325604dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "# gen.save('/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_generator_prob.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226c769-f4bd-4182-8669-8ff056ed04ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "# dis.save('/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_discriminator_prob.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc322bb7-01c3-4f14-b816-5f1f9f8d67ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ps.crps_ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55417668-f00f-49be-9702-5deaf754a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = '2021-06-15'\n",
    "date2 = '2021-09-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee2cfa-4b4a-47bd-bf3d-e24a0afc79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"CRPS: {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data) ):.4f}\")\n",
    "print(f\"MAE1: {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data.sel(number=0)) ):.4f}\")\n",
    "print(f\"MAE2: {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data.sel(number=1)) ):.4f}\")\n",
    "print(f\"MAE3: {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data.sel(number=2)) ):.4f}\")\n",
    "print(f\"MAE4: {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data.sel(number=3)) ):.4f}\")\n",
    "print(f\"MAE5: {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data.sel(number=4)) ):.4f}\")\n",
    "print(f\"MAE6: {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data.sel(number=5)) ):.4f}\")\n",
    "print(f\"MAE : {np.nanmean(ps.crps_ensemble(observations=fine_data_test, forecasts=downscaled_data.mean(dim='number')) ):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ebaa1-afa7-4fb9-a881-9eacf358b77f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.corrcoef(fine_data_test.values.flatten(), downscaled_data.values.flatten())[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f6e4e-882f-49a0-bbaf-178fe9535f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def compute_r2_with_nans(y_true, y_pred):\n",
    "    # Mask for non-NaN values\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    \n",
    "    # Filter out NaN values\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    # Compute R2 score\n",
    "    r2 = r2_score(y_true_filtered, y_pred_filtered)\n",
    "    return r2\n",
    "r2 = compute_r2_with_nans(fine_data_test.values.flatten(), downscaled_data.mean(dim='number').values.flatten())\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf31a66-4b47-4aeb-b16c-771113de4f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figs, axx = plt.subplots(figsize=(8,6))\n",
    "# axx.scatter(fine_data_test.values.flatten(), downscaled_data.values.flatten(), s=0.1, alpha=0.9, color='C0')\n",
    "# axx.plot([0,1000], [0,1000], color='red', alpha=0.9, zorder=1, ls='--')\n",
    "# axx.set_xlim(-8,500)\n",
    "# axx.set_ylim(-8,500)\n",
    "# axx.set_xlabel('Observation', size=15)\n",
    "# axx.set_ylabel('Downscaled', size=15)\n",
    "# axx.text(45,400,f'$R^2: {r2:.2f}$', color='white', size=12)\n",
    "# axx.grid(True, alpha=0.2, color='C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5790a-3a04-4728-bf1f-c44a3e63b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crps_data = ps.crps_ensemble(observations=fine_data_test.sel(time=slice(date1, date2)), \n",
    "                             forecasts=downscaled_data.sel(time=slice(date1, date2)))\n",
    "# Convert to xarray DataArray if necessary\n",
    "crps_data = xr.DataArray(crps_data, dims=[\"time\", \"lat\", \"lon\"], coords={\"time\": fine_data_test.sel(time=slice(date1, date2)).time,\n",
    "                                                                         \"lat\": fine_data_test.lat, \n",
    "                                                                         \"lon\": fine_data_test.lon,\n",
    "                                                                        })\n",
    "\n",
    "# Define the colormap colors\n",
    "colors_blues2black = [(0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "colors_RdBlBu = [(1, 0, 0), (0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "\n",
    "# Create the colormap\n",
    "cmap_name = 'BluesToBlack'\n",
    "blues_to_black = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors_blues2black)\n",
    "Rd_bl_Bu = mcolors.LinearSegmentedColormap.from_list('RdBlBu', colors_RdBlBu)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12,10), sharex=True, sharey=True,\n",
    "                        subplot_kw=dict(projection=ccrs.PlateCarree(), facecolor='black'),\n",
    "                        gridspec_kw={'wspace': -0.05, 'hspace': -0.45})\n",
    "\n",
    "# Define the plots list\n",
    "plots = [coarse_data_test, fine_data_test, downscaled_data.mean(dim='number'), crps_data]\n",
    "cmap = [blues_to_black, blues_to_black, blues_to_black, 'afmhot']\n",
    "levels = [np.arange(0,6.125,0.125), np.arange(0,6.125,0.125), np.arange(0,6.125,0.125), np.arange(0,6.125,0.125)]\n",
    "title = ['a) Coarse','b) Fine','c) Downscaled','d) CRPS']\n",
    "ticks = [np.arange(0,7,1), np.arange(0,7,1), np.arange(0,7,1), np.arange(0,7,1)]\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i != (len(plots) - 1):\n",
    "        plots[i].sel(time=slice(date1, date2)).mean('time').plot(cmap=cmap[i], levels=levels[i], \n",
    "                                                                 ax=ax, cbar_kwargs={'orientation':'vertical',\n",
    "                                                                                    'pad':0.01, 'label':'',\n",
    "                                                                                    'shrink':0.48, 'drawedges':False,\n",
    "                                                                                    'ticks': ticks[i], },\n",
    "                                                                 alpha=0.90)\n",
    "    else:\n",
    "        plots[-1].sel(time=slice(date1, date2)).mean('time').plot(cmap=cmap[i], levels=levels[i], \n",
    "                       ax=ax, cbar_kwargs={'orientation':'vertical',\n",
    "                                           'pad':0.01, 'label':'',\n",
    "                                           'shrink':0.48, 'drawedges':False,\n",
    "                                           'ticks': ticks[i], },\n",
    "                       alpha=0.90)\n",
    "    \n",
    "    ax.text(0, 55.2, f'{title[i]}', size=13, color='white')\n",
    "    ax.coastlines(linewidth=1.5, color='white')\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=1.5, edgecolor='white')\n",
    "    ax.patch.set_facecolor('black')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
