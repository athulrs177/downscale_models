{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf0ac80-aa97-43bb-8195-eb8c1fcc8692",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 10:12:57.369295: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-19 10:12:57.369353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-19 10:12:57.370638: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-19 10:12:57.391368: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-19 10:12:59.614483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import dask.array as da\n",
    "# from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Conv2DTranspose, MaxPool2D, Flatten, Conv2D, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, UpSampling2D, concatenate, Activation\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Input\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, Concatenate, LeakyReLU, Add\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import cm \n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# import properscoring as ps\n",
    "import xskillscore as xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302ac346-8a66-4805-a2d8-96e742b3bd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba0b4db-4eb1-4105-8c6f-365401ab5746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 10:13:07.573011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79086 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2024-08-19 10:13:07.574656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79086 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:44:00.0, compute capability: 8.0\n",
      "2024-08-19 10:13:07.576088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79086 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:84:00.0, compute capability: 8.0\n",
      "2024-08-19 10:13:07.577483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79086 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c4:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Get the list of available physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Set memory growth for each GPU\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Create MirroredStrategy\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\"])\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eecd1102-73ca-48ee-8f3c-ca1311d1c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diri = '/work/bb0983/athul_satheesh/e_obs_precip/'\n",
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/figures/'\n",
    "\n",
    "coarse_raw = 'rr_ens_mean_1.0deg_reg_v29.0e.nc'\n",
    "fine_raw = 'rr_ens_mean_0.1deg_reg_v29.0e.nc'\n",
    "\n",
    "lati = 43#40\n",
    "latf = 59#60\n",
    "\n",
    "loni = -6#-10\n",
    "lonf = 15#30\n",
    "\n",
    "# test period\n",
    "strt = '2001-01-01'\n",
    "last = '2023-12-31'\n",
    "\n",
    "coarse_data = xr.open_dataset(diri+coarse_raw).rr.transpose('time','lat','lon').sel(time=slice(strt, last), \n",
    "                                                                                    lat=slice(lati, latf), \n",
    "                                                                                    lon=slice(loni, lonf)\n",
    "                                                                                   )\n",
    "fine_data = xr.open_dataset(diri+fine_raw).rr.transpose('time','latitude','longitude').sel(time=slice(strt, last), \n",
    "                                                                                           latitude=slice(lati, latf), \n",
    "                                                                                           longitude=slice(loni, lonf)\n",
    "                                                                                          )\n",
    "fine_data = fine_data.rename({'latitude':'lat', 'longitude':'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e87853-66b9-4253-8766-28a99dcde5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_coarse = coarse_data.shape\n",
    "dims_fine = fine_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d6bc00-aeb6-4550-88ff-8738b01008ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_nan_mask = np.isnan(coarse_data)\n",
    "fine_nan_mask = np.isnan(fine_data)\n",
    "\n",
    "fill_val = -1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996f725a-7622-4b23-986a-833d1ea592c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_data = coarse_data.fillna(fill_val)\n",
    "fine_data = fine_data.fillna(fill_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9082ff-2a7c-4f6f-9a11-b6cd7479be12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 400 #650 #1450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f571961-9166-4f6d-b062-dccafb87a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diri = '/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/' #'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp/'\n",
    "model_fili = f'generator_prob_epoch_{epoch}_adam_crps.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6cc0037-3cb2-4429-93e3-1e43d7f9a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a custom dropout layer that is active also during prediction and use this in the model instead of the default Dropout.\n",
    "# Alternatively you can also set \"training=True\" in the Dropout layer\n",
    "@register_keras_serializable()\n",
    "class CustomDropout(Dropout):\n",
    "    def __init__(self, rate, **kwargs):\n",
    "        super(CustomDropout, self).__init__(rate, **kwargs)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        return super().call(inputs, training=True)  # Always active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42f867ce-663f-488d-98b7-0c3fea755dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # Load the generator \n",
    "    generator = load_model(model_diri+model_fili)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2665514a-6201-4e22-8ea4-00ade02a4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_downscaled_data(generator, coarse_data, fine_data, fine_nan_mask):\n",
    "    # Generate predictions for all ensemble members at once\n",
    "    with tf.device('/cpu:0'):\n",
    "        downscaled_data = generator.predict(coarse_data.values.reshape(coarse_data.shape + (1,)), batch_size=32)\n",
    "    \n",
    "    # Create a list to hold DataArrays for each ensemble member after applying the NaN mask\n",
    "    downscaled_data_list = []\n",
    "    \n",
    "    for i in range(downscaled_data.shape[-1]):\n",
    "        # Extract the i-th ensemble member\n",
    "        member_data = downscaled_data[..., i]\n",
    "        \n",
    "        # Create DataArray for the current member\n",
    "        downscaled_data_da = xr.DataArray(\n",
    "            name='precipitation',\n",
    "            data=member_data,\n",
    "            dims=fine_data.dims,\n",
    "            coords=fine_data.coords,\n",
    "            attrs=fine_data.attrs\n",
    "        )\n",
    "        \n",
    "        # Apply NaN mask to the current member\n",
    "        downscaled_data_da = downscaled_data_da.where(~fine_nan_mask, np.nan)\n",
    "        \n",
    "        # Append the masked member to the list\n",
    "        downscaled_data_list.append(downscaled_data_da)\n",
    "    \n",
    "    # Concatenate the list along the 'number' dimension\n",
    "    downscaled_data = xr.concat(downscaled_data_list, dim='number')\n",
    "    \n",
    "    # Assign 'number' coordinate and transpose to the desired order\n",
    "    # downscaled_data = downscaled_data.assign_coords(number=np.arange(downscaled_data.shape[-1]))\n",
    "    downscaled_data = downscaled_data.transpose('time', 'lat', 'lon', 'number')\n",
    "    \n",
    "    return downscaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db19a3e8-74bb-48b7-ac57-6112c82d123d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 10:13:35.179744: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape ingenerator/conv_4_dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-19 10:13:35.505896: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-19 10:13:35.507172: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-19 10:13:35.510724: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-19 10:13:35.519525: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-19 10:13:35.796695: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-19 10:13:36.402410: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 10s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 10:13:43.973096: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 56448000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 26s, sys: 15min 29s, total: 17min 55s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "downscaled_data = generate_downscaled_data(generator, coarse_data, fine_data, fine_nan_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab3fdf8b-45b6-4613-8f63-a1e7fb601b04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/downscaled_data/'\n",
    "downscaled_data.to_netcdf(f'{diro}e_obs_eu_downscaled_wgan_prob_extended_eu_{epoch}epochs_adam_crps.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bfaa76d-a7a9-408e-9b4f-fae56740ade2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# downscaled_data_mem1 = generator.predict( coarse_data.values.reshape( coarse_data.shape + (1,) ) )\n",
    "# downscaled_data_mem2 = generator.predict( coarse_data.values.reshape( coarse_data.shape + (1,) ) )\n",
    "# downscaled_data_mem3 = generator.predict( coarse_data.values.reshape( coarse_data.shape + (1,) ) )\n",
    "# downscaled_data_mem4 = generator.predict( coarse_data.values.reshape( coarse_data.shape + (1,) ) )\n",
    "# downscaled_data_mem5 = generator.predict( coarse_data.values.reshape( coarse_data.shape + (1,) ) )\n",
    "# downscaled_data_mem6 = generator.predict( coarse_data.values.reshape( coarse_data.shape + (1,) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1714fcba-70ff-4122-9ec0-5bb1b2aee408",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# downscaled_data_mem1 = xr.DataArray(name='precipitation', data=downscaled_data_mem1.squeeze(), \n",
    "#                                dims=fine_data.dims, coords=fine_data.coords, \n",
    "#                                attrs=fine_data.attrs)\n",
    "# downscaled_data_mem1 = downscaled_data_mem1.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "# downscaled_data_mem2 = xr.DataArray(name='precipitation', data=downscaled_data_mem2.squeeze(), \n",
    "#                                dims=fine_data.dims, coords=fine_data.coords, \n",
    "#                                attrs=fine_data.attrs)\n",
    "# downscaled_data_mem2 = downscaled_data_mem2.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "# downscaled_data_mem3 = xr.DataArray(name='precipitation', data=downscaled_data_mem3.squeeze(), \n",
    "#                                dims=fine_data.dims, coords=fine_data.coords, \n",
    "#                                attrs=fine_data.attrs)\n",
    "# downscaled_data_mem3 = downscaled_data_mem3.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "# downscaled_data_mem4 = xr.DataArray(name='precipitation', data=downscaled_data_mem4.squeeze(), \n",
    "#                                dims=fine_data.dims, coords=fine_data.coords, \n",
    "#                                attrs=fine_data.attrs)\n",
    "# downscaled_data_mem4 = downscaled_data_mem4.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "# downscaled_data_mem5 = xr.DataArray(name='precipitation', data=downscaled_data_mem5.squeeze(), \n",
    "#                                dims=fine_data.dims, coords=fine_data.coords, \n",
    "#                                attrs=fine_data.attrs)\n",
    "# downscaled_data_mem5 = downscaled_data_mem5.where(~fine_nan_mask, np.nan)\n",
    "\n",
    "# downscaled_data_mem6 = xr.DataArray(name='precipitation', data=downscaled_data_mem6.squeeze(), \n",
    "#                                dims=fine_data.dims, coords=fine_data.coords, \n",
    "#                                attrs=fine_data.attrs)\n",
    "# downscaled_data_mem6 = downscaled_data_mem6.where(~fine_nan_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a1030bf-0b46-44b2-8a49-1ce84d0c93a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# downscaled_data_list = [downscaled_data_mem1, downscaled_data_mem2, downscaled_data_mem3, \n",
    "#                    downscaled_data_mem4, downscaled_data_mem5, downscaled_data_mem6\n",
    "#                   ]\n",
    "# downscaled_data = xr.concat(downscaled_data_list, dim='number')\n",
    "# downscaled_data = downscaled_data.assign_coords(number=np.arange( len(downscaled_data_list)) )\n",
    "# downscaled_data = downscaled_data.transpose('time', 'lat', 'lon', 'number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "783fb070-d4d6-405d-993d-dd5f2adc5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_data = fine_data.where(~fine_nan_mask, np.nan)\n",
    "coarse_data = coarse_data.where(~coarse_nan_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e15b82-6783-4b26-a1bf-2540f34231dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE1 : 1.1203\n",
      "MAE15: 1.1281\n",
      "MAE25: 1.1291\n",
      "MAE  : 1.1192\n"
     ]
    }
   ],
   "source": [
    "# print(f\"CRPS : {np.nanmean(xs.crps_ensemble(observations=fine_data, forecasts=downscaled_data, member_dim='number') ):.4f}\")\n",
    "print(f\"MAE1 : {np.nanmean(abs(fine_data - downscaled_data.sel(number=0)) ):.4f}\")\n",
    "print(f\"MAE15: {np.nanmean(abs(fine_data - downscaled_data.sel(number=15)) ):.4f}\")\n",
    "print(f\"MAE25: {np.nanmean(abs(fine_data - downscaled_data.sel(number=25)) ):.4f}\")\n",
    "print(f\"MAE  : {np.nanmean(abs(fine_data - downscaled_data.mean('number')) ):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40165603-203a-4bfe-a088-df413420281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date1 = '2014-06-09' #'2021-06-15'\n",
    "# date2 = '2014-06-09' #'2021-09-15'\n",
    "\n",
    "# crps_data = xs.crps_ensemble(observations=fine_data.sel(time=slice(date1, date2)), \n",
    "#                              forecasts=downscaled_data.sel(time=slice(date1, date2)),\n",
    "#                             member_dim='number', dim='time')\n",
    "# # Convert to xarray DataArray if necessary\n",
    "# crps_data = xr.DataArray(crps_data, dims=[\"lat\", \"lon\"], coords={\"lat\": fine_data.lat, \n",
    "#                                                                          \"lon\": fine_data.lon,\n",
    "#                                                                         })\n",
    "\n",
    "# # Define the colormap colors\n",
    "# colors_blues2black = [(0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "# colors_RdBlBu = [(1, 0, 0), (0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "\n",
    "# # Create the colormap\n",
    "# cmap_name = 'BluesToBlack'\n",
    "# blues_to_black = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors_blues2black)\n",
    "# Rd_bl_Bu = mcolors.LinearSegmentedColormap.from_list('RdBlBu', colors_RdBlBu)\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12,10), sharex=True, sharey=True,\n",
    "#                         subplot_kw=dict(projection=ccrs.PlateCarree(), facecolor='black'),\n",
    "#                         gridspec_kw={'wspace': -0.05, 'hspace': -0.45})\n",
    "\n",
    "# # Define the plots list\n",
    "# plots = [coarse_data, fine_data, downscaled_data.mean(dim='number'), crps_data]\n",
    "# # cmap = [blues_to_black, blues_to_black, blues_to_black, 'afmhot']\n",
    "# cmap = ['turbo', 'turbo', 'turbo', 'afmhot']\n",
    "# levels = [np.arange(0,20.125,0.125), np.arange(0,20.125,0.125), np.arange(0,20.125,0.125), np.arange(0,10.125,0.125)]\n",
    "# title = ['a) Coarse','b) Fine','c) Downscaled ENS mean','d) CRPS']\n",
    "# ticks = [np.arange(0,24,4), np.arange(0,24,4), np.arange(0,24,4), np.arange(0,12,2)]\n",
    "\n",
    "# for i, ax in enumerate(axs.flatten()):\n",
    "#     if i != (len(plots) - 1):\n",
    "#         plots[i].sel(time=slice(date1, date2)).mean('time').plot(cmap=cmap[i], levels=levels[i], \n",
    "#                                                                  ax=ax, cbar_kwargs={'orientation':'vertical',\n",
    "#                                                                                     'pad':0.01, 'label':'',\n",
    "#                                                                                     'shrink':0.48, 'drawedges':False,\n",
    "#                                                                                     'ticks': ticks[i], },\n",
    "#                                                                  alpha=0.75)\n",
    "#     else:\n",
    "#         plots[-1].plot(cmap=cmap[i], levels=levels[i], \n",
    "#                        ax=ax, cbar_kwargs={'orientation':'vertical',\n",
    "#                                            'pad':0.01, 'label':'',\n",
    "#                                            'shrink':0.48, 'drawedges':False,\n",
    "#                                            'ticks': ticks[i], },\n",
    "#                        alpha=0.90)\n",
    "    \n",
    "#     ax.text(0, 55.2, f'{title[i]}', size=13, color='white')\n",
    "#     ax.coastlines(linewidth=1.5, color='white')\n",
    "#     ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=1.5, edgecolor='white')\n",
    "#     ax.patch.set_facecolor('black')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
