{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69462c4e-76ba-47a6-a78f-4ff8b63e5aea",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 10:05:41.996475: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-21 10:05:41.996530: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-21 10:05:41.997758: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-21 10:05:42.022609: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-21 10:05:44.202298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Conv2DTranspose, MaxPool2D, Flatten, Conv2D, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, UpSampling2D, concatenate, Activation\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Input\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, Concatenate, LeakyReLU, BatchNormalization, Add\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import cm \n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler = MaxAbsScaler()\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "tf.random.set_seed(42)  # to replicate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a063a2-6f1c-4924-8242-425a88cfb819",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "137f9c7f-5d41-4a53-9db0-a4a9aa56a29e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 10:05:49.931414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79086 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2024-08-21 10:05:49.933052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 79086 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:44:00.0, compute capability: 8.0\n",
      "2024-08-21 10:05:49.934495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 79086 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:84:00.0, compute capability: 8.0\n",
      "2024-08-21 10:05:49.935977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 79086 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c4:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Get the list of available physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Set memory growth for each GPU\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Create MirroredStrategy\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\"])\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d876839-26e3-482c-a342-5824d9f0c4a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diri = '/work/bb0983/athul_satheesh/e_obs_precip/'\n",
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/figures/'\n",
    "\n",
    "coarse_raw = 'rr_ens_mean_1.0deg_reg_v29.0e.nc'\n",
    "fine_raw = 'rr_ens_mean_0.1deg_reg_v29.0e.nc'\n",
    "\n",
    "lati = 43#40\n",
    "latf = 59#60\n",
    "\n",
    "loni = -6#-10\n",
    "lonf = 15#30\n",
    "\n",
    "strt = '1950-01-01'\n",
    "last = '2023-12-31'\n",
    "\n",
    "coarse_data = xr.open_dataset(diri+coarse_raw).rr.transpose('time','lat','lon').sel(time=slice(strt, last), \n",
    "                                                                                    lat=slice(lati, latf), \n",
    "                                                                                    lon=slice(loni, lonf)\n",
    "                                                                                   )\n",
    "fine_data = xr.open_dataset(diri+fine_raw).rr.transpose('time','latitude','longitude').sel(time=slice(strt, last), \n",
    "                                                                                           latitude=slice(lati, latf), \n",
    "                                                                                           longitude=slice(loni, lonf)\n",
    "                                                                                          )\n",
    "fine_data = fine_data.rename({'latitude':'lat', 'longitude':'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b5df139-59b3-4c0f-b01f-db6c717413f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_coarse = coarse_data.shape\n",
    "dims_fine = fine_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62136626-8e1a-4880-9706-1b7fbac4de4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27028, 16, 21), (27028, 160, 210))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims_coarse, dims_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e96e34b-64dd-40a1-a62c-464150bfd655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_strt = strt\n",
    "train_last = '2000-12-31'\n",
    "\n",
    "test_strt = '2001-01-01'\n",
    "test_last = last\n",
    "\n",
    "coarse_data_train = coarse_data.sel(time=slice(train_strt, train_last))#.interp(lat=fine_data.lat, lon=fine_data.lon, method='linear')\n",
    "# coarse_data_train = coarse_data_train.fillna(coarse_data_train.mean())\n",
    "coarse_data_test = coarse_data.sel(time=slice(test_strt, test_last))#.interp(lat=fine_data.lat, lon=fine_data.lon, method='linear')\n",
    "# coarse_data_test = coarse_data_test.fillna(coarse_data_test.mean())\n",
    "# print(coarse_data_train.shape, coarse_data_test.shape)\n",
    "\n",
    "fine_data_train = fine_data.sel(time=slice(train_strt, train_last))\n",
    "fine_data_test = fine_data.sel(time=slice(test_strt, test_last))\n",
    "# print(fine_data_train.shape, fine_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c02225-58ae-43f0-99e2-10aebc02f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_nan_mask = np.isnan(coarse_data_test)\n",
    "fine_nan_mask = np.isnan(fine_data_test)\n",
    "\n",
    "fill_val = -1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b631b060-a6bb-4fe6-90ac-55b42c993ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_data_train = coarse_data_train.fillna(fill_val)#.interp(lat=fine_data.lat, lon=fine_data.lon, method='linear')\n",
    "# coarse_data_train = coarse_data_train.fillna(coarse_data_train.mean())\n",
    "coarse_data_test = coarse_data_test.fillna(fill_val)#.interp(lat=fine_data.lat, lon=fine_data.lon, method='linear')\n",
    "# coarse_data_test = coarse_data_test.fillna(coarse_data_test.mean())\n",
    "# print(coarse_data_train.shape, coarse_data_test.shape)\n",
    "\n",
    "fine_data_train = fine_data_train.fillna(fill_val)\n",
    "fine_data_test = fine_data_test.fillna(fill_val)\n",
    "# print(fine_data_train.shape, fine_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df65693-9401-4fb3-b807-624a93043b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim_loss(fake_images, real_images):\n",
    "    \"\"\"\n",
    "    Computes the SSIM loss between fake and real images.\n",
    "    \n",
    "    Parameters:\n",
    "        fake_images (tf.Tensor): Generated images.\n",
    "        real_images (tf.Tensor): Real images.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: SSIM loss.\n",
    "    \"\"\"\n",
    "    ssim_index = tf.image.ssim(fake_images, real_images, max_val=1.0)\n",
    "    return 1 - tf.reduce_mean(ssim_index)\n",
    "\n",
    "def generator_loss(fake_output, fake_images, real_images, penalty_weight=15, ssim_weight=15):\n",
    "    \"\"\"\n",
    "    Generator loss function using Wasserstein loss with an added penalty term and SSIM loss.\n",
    "    \n",
    "    Parameters:\n",
    "        fake_output (tf.Tensor): Output of the discriminator when given generated images.\n",
    "        fake_images (tf.Tensor): Generated images.\n",
    "        real_images (tf.Tensor): Real images.\n",
    "        penalty_weight (float): Weight of the penalty term.\n",
    "        ssim_weight (float): Weight of the SSIM loss term.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Generator loss.\n",
    "    \"\"\"\n",
    "    wasserstein_loss = -tf.reduce_mean(fake_output)\n",
    "    \n",
    "    # Penalty term for deviation from real outputs\n",
    "    # penalty = penalty_weight * tf.reduce_mean(tf.abs(fake_output - real_output))\n",
    "    penalty = penalty_weight * tf.reduce_mean(tf.abs(fake_images - real_images))\n",
    "    \n",
    "    # SSIM loss\n",
    "    ssim_loss_value = ssim_loss(fake_images, real_images)\n",
    "    \n",
    "    return wasserstein_loss + penalty + ssim_weight * ssim_loss_value\n",
    "    # return wasserstein_loss + ssim_weight * ssim_loss_value\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    \"\"\"\n",
    "    Discriminator loss function using Wasserstein loss.\n",
    "    \n",
    "    Parameters:\n",
    "        real_output (tf.Tensor): Output of the discriminator when given real images.\n",
    "        fake_output (tf.Tensor): Output of the discriminator when given generated images.\n",
    "    \n",
    "    Returns:\n",
    "        tf.Tensor: Discriminator loss.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8dfff4f-9339-4189-93bc-156b79d5514d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Weight clipping\n",
    "def clip_weights(model, clip_value):\n",
    "    \"\"\"\n",
    "    Clips the weights of the model to be within the range [-clip_value, clip_value].\n",
    "    \n",
    "    Parameters:\n",
    "        model (tf.keras.Model): The model whose weights will be clipped.\n",
    "        clip_value (float): The value to clip the weights to.\n",
    "    \"\"\"\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            kernel = layer.kernel\n",
    "            clipped_kernel = tf.clip_by_value(kernel, -clip_value, clip_value)\n",
    "            layer.kernel.assign(clipped_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d1e80a-5fd7-4262-8fcc-e4b28f96fe35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filters, kernel_size, name, dilation_rate, strides=(1,1), use_batch_norm=True, use_dropout=True):\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, dilation_rate=dilation_rate, strides=strides, padding='same', \n",
    "               kernel_initializer=he_normal(), name=name+'_conv')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=name+'_lrelu')(x)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization(name=name+'_bn')(x)\n",
    "    if use_dropout:\n",
    "        x = Dropout(0.25, name=name+'_dropout')(x, training=True)\n",
    "    return x\n",
    "\n",
    "def deconv_block(x, filters, kernel_size, strides, name, dilation_rate, use_batch_norm=True, use_dropout=True):\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=kernel_size, dilation_rate=dilation_rate, strides=strides, \n",
    "                        padding='same', kernel_initializer=he_normal(), name=name+'_deconv')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name=name+'_lrelu')(x)\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization(name=name+'_bn')(x)\n",
    "    if use_dropout:\n",
    "        x = Dropout(0.25, name=name+'_dropout')(x, training=True)\n",
    "    return x\n",
    "\n",
    "# def upsampling_block(inputs, filters, kernel_size, upsample_factor, name, dilation_rate, strides, use_batch_norm=True, use_dropout=True):\n",
    "#     x = UpSampling2D(size=upsample_factor, name=name+'_upsample')(inputs)\n",
    "#     x = Conv2D(filters, kernel_size, dilation_rate=dilation_rate, padding='same', strides=strides,\n",
    "#                kernel_initializer=he_normal(), name=name+'_conv')(x)\n",
    "#     x = LeakyReLU(alpha=0.2, name=name+'_lrelu')(x)\n",
    "#     if use_batch_norm:\n",
    "#         x = BatchNormalization(name=name+'_bn')(x)\n",
    "#     if use_dropout:\n",
    "#         x = Dropout(0.25, name=name+'_dropout')(x, training=True)\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fad772e-73f3-4bb8-87c2-5243d70ea2e2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def build_generator(input_shape):\n",
    "#     inputs = Input(shape=input_shape, name='generator_input')\n",
    "\n",
    "#     # Downsampling\n",
    "#     downsample_3 = conv_block(inputs, 512, (3, 3), 'downsample_3', (1,1))\n",
    "#     downsample_2 = conv_block(downsample_3, 256, (3, 3), 'downsample_2', (1,1))\n",
    "#     downsample_1 = conv_block(downsample_2, 128, (3, 3), 'downsample_1', (1,1))\n",
    "#     downsample_0 = conv_block(downsample_1, 64, (3, 3), 'downsample_0', (1,1))\n",
    "\n",
    "#     # Bottleneck\n",
    "#     bottleneck_0 = conv_block(downsample_0, 32, (3, 3), 'bottleneck_0', (1,1))\n",
    "#     bottleneck_00 = conv_block(bottleneck_0, 32, (3, 3), 'bottleneck_00', (1,1))\n",
    "\n",
    "#     # Upsampling\n",
    "#     upsample_0 = upsampling_block(bottleneck_00, 64, (3, 3), (1,1), 'upsample_0', (1,1), (1,1))\n",
    "#     upsample_1 = upsampling_block(upsample_0, 128, (3, 3), (1,1), 'upsample_1', (1,1), (1,1))\n",
    "#     upsample_2 = upsampling_block(upsample_1, 256, (3, 3), (2,2), 'upsample_2', (1,1), (1,1))\n",
    "#     upsample_3 = upsampling_block(upsample_2, 512, (6, 6), (5,5), 'upsample_3', (1,1), (1,1))\n",
    "    \n",
    "#     # Final Upsample to required shape\n",
    "#     outputs = Conv2D(filters=1, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "#                               strides=(1, 1), activation='relu', name='final_upsample_conv')(upsample_3)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5ed50c6-6759-4437-a882-e1c43c45b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(input_shape):\n",
    "    inputs = Input(shape=input_shape, name='generator_input')\n",
    "\n",
    "    # Convolutions\n",
    "    conv_4 = conv_block(inputs, 16, (3, 3), 'conv_4', (1,1), use_dropout=False)\n",
    "    conv_3 = conv_block(conv_4, 32, (3, 3), 'conv_3', (1,1), use_dropout=False)\n",
    "    conv_2 = conv_block(conv_3, 64, (3, 3), 'conv_2', (1,1), use_dropout=False)\n",
    "    conv_1 = conv_block(conv_2, 128, (3, 3), 'conv_1', (1,1), use_dropout=False)\n",
    "    conv_0 = conv_block(conv_1, 256, (3, 3), 'conv_0', (1,1), use_dropout=False)\n",
    "    conv_00 = conv_block(conv_0, 512, (3, 3), 'conv_00', (1,1), use_dropout=False)\n",
    "    \n",
    "    # Upsampling\n",
    "    deconv_00 = deconv_block(conv_00, 512, (3, 3), (1,1), 'deconv_00', (1,1), use_dropout=False)\n",
    "    deconv_0 = deconv_block(deconv_00, 256, (3, 3), (1,1), 'deconv_0', (1,1), use_dropout=False)\n",
    "    deconv_1 = deconv_block(deconv_0, 128, (3, 3), (1,1), 'deconv_1', (1,1), use_dropout=False)\n",
    "    deconv_2 = deconv_block(deconv_1, 64, (3, 3), (1,1), 'deconv_2', (1,1), use_dropout=False)\n",
    "    # deconv_3 = deconv_block(deconv_2, 32, (3, 3), (2,2), 'deconv_3', (1,1), use_dropout=False)\n",
    "    deconv_3 = deconv_block(deconv_2, 32, (3, 3), (1,1), 'deconv_3', (1,1), use_dropout=False)\n",
    "    deconv_4 = deconv_block(deconv_3, 16, (6, 6), (5,5), 'deconv_4', (1,1), use_dropout=False)\n",
    "    \n",
    "    # Final Upsample to required shape\n",
    "    # outputs = Conv2D(filters=1, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "    #                           strides=(1, 1), activation='relu', name='final_conv')(deconv_4)\n",
    "    outputs = Conv2DTranspose(filters=1, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "                              strides=(2, 2), activation='relu', name='final_deconv')(deconv_4)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3ce017a-f304-4f87-89a0-5a89e956babd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator(input_shape):\n",
    "    input_layer = Input(shape=input_shape, name='discriminator_input')\n",
    "\n",
    "    # x = conv_block(input_layer, filters=16, kernel_size=(3, 3), name='conv1', dilation_rate=(1,1), strides=(2,2), use_dropout=False)\n",
    "    x = conv_block(input_layer, filters=128, kernel_size=(3, 3), name='conv2', dilation_rate=(1,1), strides=(2,2), use_dropout=False)\n",
    "    # x = conv_block(x, filters=64, kernel_size=(3, 3), name='conv3', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "    x = conv_block(x, filters=256, kernel_size=(3, 3), name='conv4', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "    # x = conv_block(x, filters=256, kernel_size=(3, 3), name='conv5', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "    x = conv_block(x, filters=512, kernel_size=(3, 3), name='conv6', dilation_rate=(1,1), strides=(1,1), use_dropout=False)\n",
    "        \n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    # output_layer = Dense(1, activation='linear')(x)\n",
    "    output_layer = Conv2D(filters=1, kernel_size=(3, 3), padding='same', activation='linear', name='final_conv')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer, name='wGAN_discriminator')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b4a52d5-1aef-4f4f-b49a-e04f42afe606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "input_shape  = dims_coarse[1:] + (1,)\n",
    "output_shape = dims_fine[1:] + (1,)\n",
    "\n",
    "# lr = 0.5e-5\n",
    "gen_lr = 2e-4\n",
    "dis_lr = 2e-4\n",
    "clip_value = 1e-3\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    # gen_optimizer = RMSprop(learning_rate=lr, momentum=0.5)\n",
    "    # dis_optimizer = RMSprop(learning_rate=lr, momentum=0.5)\n",
    "    gen_optimizer = Adam(learning_rate=gen_lr)\n",
    "    dis_optimizer = Adam(learning_rate=dis_lr)\n",
    "    \n",
    "    gen = build_generator(input_shape)\n",
    "    dis = build_discriminator(output_shape)\n",
    "\n",
    "    gen.compile(optimizer=gen_optimizer,)\n",
    "    dis.compile(optimizer=dis_optimizer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4838ac4-2d1f-46a0-9bf3-acc9bcee8ece",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " generator_input (InputLaye  [(None, 16, 21, 1)]       0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " conv_4_conv (Conv2D)        (None, 16, 21, 16)        160       \n",
      "                                                                 \n",
      " conv_4_lrelu (LeakyReLU)    (None, 16, 21, 16)        0         \n",
      "                                                                 \n",
      " conv_4_bn (BatchNormalizat  (None, 16, 21, 16)        64        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_3_conv (Conv2D)        (None, 16, 21, 32)        4640      \n",
      "                                                                 \n",
      " conv_3_lrelu (LeakyReLU)    (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " conv_3_bn (BatchNormalizat  (None, 16, 21, 32)        128       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_2_conv (Conv2D)        (None, 16, 21, 64)        18496     \n",
      "                                                                 \n",
      " conv_2_lrelu (LeakyReLU)    (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " conv_2_bn (BatchNormalizat  (None, 16, 21, 64)        256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_1_conv (Conv2D)        (None, 16, 21, 128)       73856     \n",
      "                                                                 \n",
      " conv_1_lrelu (LeakyReLU)    (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " conv_1_bn (BatchNormalizat  (None, 16, 21, 128)       512       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_0_conv (Conv2D)        (None, 16, 21, 256)       295168    \n",
      "                                                                 \n",
      " conv_0_lrelu (LeakyReLU)    (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " conv_0_bn (BatchNormalizat  (None, 16, 21, 256)       1024      \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_00_conv (Conv2D)       (None, 16, 21, 512)       1180160   \n",
      "                                                                 \n",
      " conv_00_lrelu (LeakyReLU)   (None, 16, 21, 512)       0         \n",
      "                                                                 \n",
      " conv_00_bn (BatchNormaliza  (None, 16, 21, 512)       2048      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " deconv_00_deconv (Conv2DTr  (None, 16, 21, 512)       2359808   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " deconv_00_lrelu (LeakyReLU  (None, 16, 21, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " deconv_00_bn (BatchNormali  (None, 16, 21, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " deconv_0_deconv (Conv2DTra  (None, 16, 21, 256)       1179904   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_0_lrelu (LeakyReLU)  (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " deconv_0_bn (BatchNormaliz  (None, 16, 21, 256)       1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_1_deconv (Conv2DTra  (None, 16, 21, 128)       295040    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_1_lrelu (LeakyReLU)  (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " deconv_1_bn (BatchNormaliz  (None, 16, 21, 128)       512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_2_deconv (Conv2DTra  (None, 16, 21, 64)        73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_2_lrelu (LeakyReLU)  (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " deconv_2_bn (BatchNormaliz  (None, 16, 21, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_3_deconv (Conv2DTra  (None, 16, 21, 32)        18464     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_3_lrelu (LeakyReLU)  (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " deconv_3_bn (BatchNormaliz  (None, 16, 21, 32)        128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_4_deconv (Conv2DTra  (None, 80, 105, 16)       18448     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_4_lrelu (LeakyReLU)  (None, 80, 105, 16)       0         \n",
      "                                                                 \n",
      " deconv_4_bn (BatchNormaliz  (None, 80, 105, 16)       64        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " final_deconv (Conv2DTransp  (None, 160, 210, 1)       145       \n",
      " ose)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5526145 (21.08 MB)\n",
      "Trainable params: 5522113 (21.07 MB)\n",
      "Non-trainable params: 4032 (15.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a532b24-5242-48d5-b62c-df4de0b79378",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wGAN_discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " discriminator_input (Input  [(None, 160, 210, 1)]     0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " conv2_conv (Conv2D)         (None, 80, 105, 128)      1280      \n",
      "                                                                 \n",
      " conv2_lrelu (LeakyReLU)     (None, 80, 105, 128)      0         \n",
      "                                                                 \n",
      " conv2_bn (BatchNormalizati  (None, 80, 105, 128)      512       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv4_conv (Conv2D)         (None, 80, 105, 256)      295168    \n",
      "                                                                 \n",
      " conv4_lrelu (LeakyReLU)     (None, 80, 105, 256)      0         \n",
      "                                                                 \n",
      " conv4_bn (BatchNormalizati  (None, 80, 105, 256)      1024      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv6_conv (Conv2D)         (None, 80, 105, 512)      1180160   \n",
      "                                                                 \n",
      " conv6_lrelu (LeakyReLU)     (None, 80, 105, 512)      0         \n",
      "                                                                 \n",
      " conv6_bn (BatchNormalizati  (None, 80, 105, 512)      2048      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 40, 52, 512)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40, 52, 512)       0         \n",
      "                                                                 \n",
      " final_conv (Conv2D)         (None, 40, 52, 1)         4609      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1484801 (5.66 MB)\n",
      "Trainable params: 1483009 (5.66 MB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dis.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "160299f8-d49d-4cc5-90fa-c48fc83fc019",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "def preprocess_data(data):\n",
    "    data = tf.convert_to_tensor(data.values, dtype=tf.float32)\n",
    "    return tf.reshape(data, data.shape + (1,))\n",
    "# Compute and update gradients\n",
    "def train_step(coarse_data_batch, fine_data_batch, dis, clip_value):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "        fake_data_batch = gen(coarse_data_batch, training=True)\n",
    "        real_output = dis(fine_data_batch, training=True)\n",
    "        fake_output = dis(fake_data_batch, training=True)\n",
    "        gen_loss = generator_loss(fake_output, fake_data_batch, fine_data_batch)\n",
    "        dis_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_gen = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "    gradients_of_dis = dis_tape.gradient(dis_loss, dis.trainable_variables)\n",
    "    \n",
    "    gen_optimizer.apply_gradients(zip(gradients_of_gen, gen.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(gradients_of_dis, dis.trainable_variables))\n",
    "    \n",
    "    # Clip discriminator weights\n",
    "    clip_weights(dis, clip_value)\n",
    "    \n",
    "    return gen_loss, dis_loss\n",
    "\n",
    "@tf.function\n",
    "def distributed_train_step(coarse_data_batch, fine_data_batch, dis, clip_value):\n",
    "    per_replica_gen_losses, per_replica_dis_losses = strategy.run(train_step, args=(coarse_data_batch, fine_data_batch, dis, clip_value))\n",
    "    mean_gen_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_gen_losses, axis=None)\n",
    "    mean_dis_loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_dis_losses, axis=None)\n",
    "    return mean_gen_loss, mean_dis_loss\n",
    "\n",
    "def train_gan(gen, dis, coarse_data_train, fine_data_train, clip_value, epochs, batch_size, save_intermediate=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((preprocess_data(coarse_data_train), preprocess_data(fine_data_train)))\n",
    "    # dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).repeat(epochs)\n",
    "    dataset = dataset.shuffle(buffer_size=365*2).batch(batch_size)#.repeat(epochs)\n",
    "    distributed_dataset = strategy.experimental_distribute_dataset(dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_gen_loss = 0.0\n",
    "        total_dis_loss = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for coarse_data_batch, fine_data_batch in distributed_dataset:\n",
    "            gen_loss, dis_loss = distributed_train_step(coarse_data_batch, fine_data_batch, dis, clip_value)\n",
    "            total_gen_loss += gen_loss\n",
    "            total_dis_loss += dis_loss\n",
    "            num_batches += 1\n",
    "\n",
    "        avg_gen_loss = total_gen_loss / num_batches\n",
    "        avg_dis_loss = total_dis_loss / num_batches\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Generator Loss: {avg_gen_loss:.5f}, Discriminator Loss: {avg_dis_loss:.5f}\")\n",
    "\n",
    "        # Save models every 100 epochs\n",
    "        if save_intermediate:\n",
    "            if (epoch + 1) % 50 == 0:\n",
    "                gen.save(f'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/generator_det_epoch_{epoch+1}_adamV2.keras')\n",
    "                dis.save(f'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/discriminator_det_epoch_{epoch+1}_adamV2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0536200-3174-49d6-9da3-ccbc65b1000a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def normalize_data(dataset, scaler, train=True):\n",
    "    \n",
    "#     dims = dataset.shape\n",
    "    \n",
    "#     dataset = dataset.values.reshape(-1, dims[1]*dims[2])\n",
    "\n",
    "#     if train:\n",
    "#         normalized_data = scaler.fit_transform(dataset)\n",
    "#     else:\n",
    "#         normalized_data = scaler.transform(dataset)\n",
    "        \n",
    "#     normalized_data = normalized_data.reshape(dims + (1,) ) # Make 4D\n",
    "    \n",
    "#     return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dd48624-396c-4587-af41-bbd009eb9d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 850 \n",
    "batch_size = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "015e29b3-4acf-4a3b-87c2-9024a8313cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 10:06:41.362005: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 50 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 50 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 10:06:56.976663: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inreplica_1/wGAN_discriminator/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-21 10:06:58.637152: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-21 10:06:58.638753: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-21 10:06:58.653504: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-21 10:06:58.786723: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-21 10:06:58.880567: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-21 10:09:17.706583: I external/local_xla/xla/service/service.cc:168] XLA service 0x5555667f69d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-08-21 10:09:17.706619: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-08-21 10:09:17.706624: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-08-21 10:09:17.706628: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (2): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-08-21 10:09:17.706632: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (3): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-08-21 10:09:17.719834: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724227757.893062 2502883 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Collective all_reduce tensors: 50 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n",
      "INFO:tensorflow:Collective all_reduce tensors: 14 all_reduces, num_devices = 4, group_size = 4, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-21 10:09:46.524460: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inreplica_1/wGAN_discriminator/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Generator Loss: 69.29475, Discriminator Loss: -2.89883\n",
      "Epoch 20, Generator Loss: 51.21533, Discriminator Loss: -1.60669\n",
      "Epoch 30, Generator Loss: 48.69393, Discriminator Loss: -2.56933\n",
      "Epoch 40, Generator Loss: 44.09278, Discriminator Loss: -2.28906\n",
      "Epoch 50, Generator Loss: 43.35353, Discriminator Loss: -2.02308\n",
      "Epoch 60, Generator Loss: 41.35925, Discriminator Loss: -1.51731\n",
      "Epoch 70, Generator Loss: 39.80731, Discriminator Loss: -1.56497\n",
      "Epoch 80, Generator Loss: 39.02605, Discriminator Loss: -1.52147\n",
      "Epoch 90, Generator Loss: 38.68588, Discriminator Loss: -1.47390\n",
      "Epoch 100, Generator Loss: 37.21851, Discriminator Loss: -1.40994\n",
      "Epoch 110, Generator Loss: 37.45939, Discriminator Loss: -1.51143\n",
      "Epoch 120, Generator Loss: 36.09889, Discriminator Loss: -1.67824\n",
      "Epoch 130, Generator Loss: 36.44900, Discriminator Loss: -1.03741\n",
      "Epoch 140, Generator Loss: 35.68258, Discriminator Loss: -1.24069\n",
      "Epoch 150, Generator Loss: 34.53704, Discriminator Loss: -1.28347\n",
      "Epoch 160, Generator Loss: 33.26230, Discriminator Loss: -1.55179\n",
      "Epoch 170, Generator Loss: 33.89917, Discriminator Loss: -1.39749\n",
      "Epoch 180, Generator Loss: 33.01545, Discriminator Loss: -1.45389\n",
      "Epoch 190, Generator Loss: 31.83837, Discriminator Loss: -1.58223\n",
      "Epoch 200, Generator Loss: 31.46890, Discriminator Loss: -1.44861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_gan(gen, dis, coarse_data_train, fine_data_train, clip_value, epochs, batch_size, save_intermediate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a85eee6-8a66-479c-9203-07aa6c449b68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def inverse_normalize_data(normalized_data, scaler):\n",
    "    \n",
    "#     dims = normalized_data.shape\n",
    "    \n",
    "#     normalized_data = normalized_data.reshape(-1, dims[1]*dims[2])\n",
    "    \n",
    "#     original_data = scaler.inverse_transform(normalized_data)\n",
    "    \n",
    "#     original_data = original_data.reshape(dims)\n",
    "#     return original_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4468dabb-f8c7-4821-9ff1-5e665193a832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "downscaled_data = gen.predict( coarse_data_test.values.reshape( coarse_data_test.shape + (1,) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0cf8a-a50d-44e7-b636-0e8536cd67b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downscaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fd189-3b3f-4ba1-89f0-ee4fa0fc4e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downscaled_data = inverse_normalize_data(downscaled_data, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f0bed-cbf5-4571-b4ca-37537adab2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downscaled_data = xr.DataArray(name='precipitation', data=downscaled_data.squeeze(), \n",
    "                               dims=fine_data_test.dims, coords=fine_data_test.coords, \n",
    "                               attrs=fine_data_test.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af789b1c-4f8d-4bfb-8636-f0019fc72d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscaled_data = downscaled_data.where(~fine_nan_mask, np.nan)\n",
    "fine_data_test = fine_data_test.where(~fine_nan_mask, np.nan)\n",
    "coarse_data_test = coarse_data_test.where(~coarse_nan_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e60550-1412-4666-9aef-ef1405a582a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/downscaled_data/'\n",
    "# downscaled_data.to_netcdf(diro + 'e_obs_eu_downscaled_wgan_det.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c82756-fa6d-4a2b-8099-a0e6325604dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "# gen.save('/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_generator_transpose.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226c769-f4bd-4182-8669-8ff056ed04ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "# dis.save('/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_discriminator_transpose.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdee2cfa-4b4a-47bd-bf3d-e24a0afc79a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date1 = '2021-06-15'\n",
    "date2 = '2021-09-15'\n",
    "\n",
    "print(f\"MAE: {abs(fine_data_test - downscaled_data).mean().values:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt( ( (fine_data_test - downscaled_data)**2 ).mean() ).values:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6ebaa1-afa7-4fb9-a881-9eacf358b77f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.corrcoef(fine_data_test.values.flatten(), downscaled_data.values.flatten())[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f6e4e-882f-49a0-bbaf-178fe9535f40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def compute_r2_with_nans(y_true, y_pred):\n",
    "    # Mask for non-NaN values\n",
    "    mask = ~np.isnan(y_true) & ~np.isnan(y_pred)\n",
    "    \n",
    "    # Filter out NaN values\n",
    "    y_true_filtered = y_true[mask]\n",
    "    y_pred_filtered = y_pred[mask]\n",
    "    \n",
    "    # Compute R2 score\n",
    "    r2 = r2_score(y_true_filtered, y_pred_filtered)\n",
    "    return r2\n",
    "r2 = compute_r2_with_nans(fine_data_test.values.flatten(), downscaled_data.values.flatten())\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf31a66-4b47-4aeb-b16c-771113de4f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# figs, axx = plt.subplots(figsize=(8,6))\n",
    "# axx.scatter(fine_data_test.values.flatten(), downscaled_data.values.flatten(), s=0.1, alpha=0.9, color='C0')\n",
    "# axx.plot([0,1000], [0,1000], color='red', alpha=0.9, zorder=1, ls='--')\n",
    "# axx.set_xlim(-8,500)\n",
    "# axx.set_ylim(-8,500)\n",
    "# axx.set_xlabel('Observation', size=15)\n",
    "# axx.set_ylabel('Downscaled', size=15)\n",
    "# axx.text(45,400,f'$R^2: {r2:.2f}$', color='white', size=12)\n",
    "# axx.grid(True, alpha=0.2, color='C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5790a-3a04-4728-bf1f-c44a3e63b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the colormap colors\n",
    "colors_blues2black = [(0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "colors_RdBlBu = [(1, 0, 0), (0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "\n",
    "# Create the colormap\n",
    "cmap_name = 'BluesToBlack'\n",
    "blues_to_black = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors_blues2black)\n",
    "Rd_bl_Bu = mcolors.LinearSegmentedColormap.from_list('RdBlBu', colors_RdBlBu)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12,10), sharex=True, sharey=True,\n",
    "                        subplot_kw=dict(projection=ccrs.PlateCarree(), facecolor='black'),\n",
    "                        gridspec_kw={'wspace': -0.05, 'hspace': -0.45})\n",
    "\n",
    "# plots = [coarse_data_test, fine_data_test, downscaled_data, (fine_data_test - downscaled_data)]\n",
    "plots = [coarse_data_test, fine_data_test, downscaled_data, abs(fine_data_test - downscaled_data)]\n",
    "cmap = [blues_to_black, blues_to_black, blues_to_black, 'afmhot']\n",
    "# cmap = [blues_to_black, blues_to_black, blues_to_black, Rd_bl_Bu]\n",
    "# levels = [np.arange(0,30.25,0.25), np.arange(0,30.25,0.25), np.arange(0,30.25,0.25), np.arange(-12,12.25,0.25)]\n",
    "levels = [np.arange(0,6.125,0.125), np.arange(0,6.125,0.125), np.arange(0,6.125,0.125), np.arange(0,6.125,0.125)]\n",
    "# title = ['a) Coarse','b) Fine','c) Downscaled','d) Observed-Downscaled']\n",
    "title = ['a) Coarse','b) Fine','c) Downscaled','d) MAE']\n",
    "# ticks = [np.arange(0,33,3), np.arange(0,33,3), np.arange(0,33,3), np.arange(-12,13,4)]\n",
    "ticks = [np.arange(0,7,1), np.arange(0,7,1), np.arange(0,7,1), np.arange(0,7,1)]\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    plots[i].sel(time=slice(date1, date2)).mean('time').plot(cmap=cmap[i], levels=levels[i], \n",
    "                                                             ax=ax, cbar_kwargs={'orientation':'vertical',\n",
    "                                                                                'pad':0.01, 'label':'',\n",
    "                                                                                'shrink':0.48, 'drawedges':False,\n",
    "                                                                                'ticks': ticks[i], },\n",
    "                                                            alpha=0.90)\n",
    "    \n",
    "    ax.text(0, 55.2, f'{title[i]}',size=13, color='white')\n",
    "    ax.coastlines(linewidth=1.5, color='white')\n",
    "    ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=1.5, edgecolor='white');\n",
    "    ax.patch.set_facecolor('black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
