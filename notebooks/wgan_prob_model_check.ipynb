{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf0ac80-aa97-43bb-8195-eb8c1fcc8692",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 15:47:00.224284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 15:47:00.224334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 15:47:00.225457: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 15:47:00.243444: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 15:47:02.707677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import dask.array as da\n",
    "# from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Concatenate, Conv2DTranspose, MaxPool2D, Flatten, Conv2D, Reshape, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import LeakyReLU, BatchNormalization, UpSampling2D, concatenate, Activation\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.models import load_model\n",
    "# from keras.saving import register_keras_serializable\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2DTranspose, Input\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Dropout, Concatenate, LeakyReLU, Add\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import cm \n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# import properscoring as ps\n",
    "import xskillscore as xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "302ac346-8a66-4805-a2d8-96e742b3bd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ba0b4db-4eb1-4105-8c6f-365401ab5746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 15:47:11.484623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12058 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2024-08-29 15:47:11.487250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 12164 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:44:00.0, compute capability: 8.0\n",
      "2024-08-29 15:47:11.489743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 12164 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:84:00.0, compute capability: 8.0\n",
      "2024-08-29 15:47:11.492270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 12188 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:c4:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Get the list of available physical GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# Set memory growth for each GPU\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Create MirroredStrategy\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "# strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\"])\n",
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\", \"/gpu:3\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eecd1102-73ca-48ee-8f3c-ca1311d1c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diri = '/work/bb0983/athul_satheesh/e_obs_precip/'\n",
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/figures/'\n",
    "\n",
    "coarse_raw = 'rr_ens_mean_1.0deg_reg_v29.0e.nc'\n",
    "fine_raw = 'rr_ens_mean_0.1deg_reg_v29.0e.nc'\n",
    "\n",
    "lati = 43#40\n",
    "latf = 59#60\n",
    "\n",
    "loni = -6#-10\n",
    "lonf = 15#30\n",
    "\n",
    "# test period\n",
    "strt = '2001-01-01'\n",
    "last = '2023-12-31'\n",
    "\n",
    "coarse_data = xr.open_dataset(diri+coarse_raw).rr.transpose('time','lat','lon').sel(time=slice(strt, last), \n",
    "                                                                                    lat=slice(lati, latf), \n",
    "                                                                                    lon=slice(loni, lonf)\n",
    "                                                                                   )\n",
    "fine_data = xr.open_dataset(diri+fine_raw).rr.transpose('time','latitude','longitude').sel(time=slice(strt, last), \n",
    "                                                                                           latitude=slice(lati, latf), \n",
    "                                                                                           longitude=slice(loni, lonf)\n",
    "                                                                                          )\n",
    "fine_data = fine_data.rename({'latitude':'lat', 'longitude':'lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e87853-66b9-4253-8766-28a99dcde5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_coarse = coarse_data.shape# def build_generator(input_shape):\n",
    "#     inputs = Input(shape=input_shape, name='generator_input')\n",
    "\n",
    "#     # Convolutions\n",
    "#     conv_4 = conv_block(inputs, 16, (3, 3), 'conv_4', (1,1))\n",
    "#     conv_3 = conv_block(conv_4, 32, (3, 3), 'conv_3', (1,1))\n",
    "#     conv_2 = conv_block(conv_3, 64, (3, 3), 'conv_2', (1,1))\n",
    "#     conv_1 = conv_block(conv_2, 128, (3, 3), 'conv_1', (1,1))\n",
    "#     conv_0 = conv_block(conv_1, 256, (3, 3), 'conv_0', (1,1))\n",
    "#     conv_00 = conv_block(conv_0, 512, (3, 3), 'conv_00', (1,1))\n",
    "    \n",
    "#     # Upsampling\n",
    "#     deconv_00 = deconv_block(conv_00, 512, (3, 3), (1,1), 'deconv_00', (1,1))\n",
    "#     deconv_0 = deconv_block(deconv_00, 256, (3, 3), (1,1), 'deconv_0', (1,1))\n",
    "#     deconv_1 = deconv_block(deconv_0, 128, (3, 3), (1,1), 'deconv_1', (1,1))\n",
    "#     deconv_2 = deconv_block(deconv_1, 64, (3, 3), (1,1), 'deconv_2', (1,1))\n",
    "#     # deconv_3 = deconv_block(deconv_2, 32, (3, 3), (2,2), 'deconv_3', (1,1))\n",
    "#     deconv_3 = deconv_block(deconv_2, 32, (3, 3), (1,1), 'deconv_3', (1,1))\n",
    "#     deconv_4 = deconv_block(deconv_3, 16, (6, 6), (5,5), 'deconv_4', (1,1))\n",
    "    \n",
    "#     # Final Upsample to required shape\n",
    "#     # outputs = Conv2D(filters=1, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "#     #                           strides=(1, 1), activation='relu', name='final_conv')(deconv_4)\n",
    "#     outputs = Conv2DTranspose(filters=1, kernel_size=(3, 3), kernel_initializer=he_normal(), padding='same', \n",
    "#                               strides=(2, 2), activation='relu', name='final_deconv')(deconv_4)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    \n",
    "#     return model\n",
    "dims_fine = fine_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d6bc00-aeb6-4550-88ff-8738b01008ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_nan_mask = np.isnan(coarse_data)\n",
    "fine_nan_mask = np.isnan(fine_data)\n",
    "\n",
    "fill_val = -1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "996f725a-7622-4b23-986a-833d1ea592c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_data = coarse_data.fillna(fill_val)\n",
    "fine_data = fine_data.fillna(fill_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9082ff-2a7c-4f6f-9a11-b6cd7479be12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch = 1800 #1450 #650 #500 #1500 #650 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58faa55e-bd9e-4280-9600-e5511b840b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @register_keras_serializable()\n",
    "# class RandomDropout(tf.keras.layers.Dropout):\n",
    "#     def __init__(self, min_rate=0.25, max_rate=0.35, **kwargs):\n",
    "#         # Pass a dummy rate (e.g., 0.0) to satisfy the base class constructor\n",
    "#         super(RandomDropout, self).__init__(rate=0.0, **kwargs)\n",
    "#         self.min_rate = min_rate\n",
    "#         self.max_rate = max_rate\n",
    "\n",
    "#     def call(self, inputs, training=None):\n",
    "#         # Apply dropout with a random rate between min_rate and max_rate\n",
    "#         self.rate = np.random.uniform(self.min_rate, self.max_rate)\n",
    "#         return super(RandomDropout, self).call(inputs, training=True)  # Force dropout always\n",
    "\n",
    "#     def get_config(self):\n",
    "#         config = super(RandomDropout, self).get_config()\n",
    "#         config.update({\n",
    "#             'min_rate': self.min_rate,\n",
    "#             'max_rate': self.max_rate,\n",
    "#         })\n",
    "#         return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f571961-9166-4f6d-b062-dccafb87a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diri = '/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp_extended_eu/' #'/work/bb0983/athul_satheesh/downscaled_data/europe/trained_models/wgan_gp/'\n",
    "model_fili = f'generator_prob_epoch_{epoch}_adamV5.keras'\n",
    "model_fili_dis = f'discriminator_prob_epoch_{epoch}_adamV5.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6cc0037-3cb2-4429-93e3-1e43d7f9a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use a custom dropout layer that is active also during prediction and use this in the model instead of the default Dropout.\n",
    "# # Alternatively you can also set \"training=True\" in the Dropout layer\n",
    "# @register_keras_serializable()\n",
    "# class CustomDropout(Dropout):\n",
    "#     def __init__(self, rate, **kwargs):\n",
    "#         super(CustomDropout, self).__init__(rate, **kwargs)\n",
    "\n",
    "#     def call(self, inputs, training=None):\n",
    "#         return super().call(inputs, training=True)  # Always active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42f867ce-663f-488d-98b7-0c3fea755dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # Load the generator \n",
    "    generator = load_model(model_diri+model_fili)\n",
    "    discriminator = load_model(model_diri+model_fili_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4c2b964-21b3-466e-916d-ee7b5d150d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " generator_input (InputLaye  [(None, 16, 21, 1)]       0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " conv_4_conv (Conv2D)        (None, 16, 21, 16)        160       \n",
      "                                                                 \n",
      " conv_4_lrelu (LeakyReLU)    (None, 16, 21, 16)        0         \n",
      "                                                                 \n",
      " conv_4_bn (BatchNormalizat  (None, 16, 21, 16)        64        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_4_dropout (Dropout)    (None, 16, 21, 16)        0         \n",
      "                                                                 \n",
      " conv_3_conv (Conv2D)        (None, 16, 21, 32)        4640      \n",
      "                                                                 \n",
      " conv_3_lrelu (LeakyReLU)    (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " conv_3_bn (BatchNormalizat  (None, 16, 21, 32)        128       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_3_dropout (Dropout)    (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " conv_2_conv (Conv2D)        (None, 16, 21, 64)        18496     \n",
      "                                                                 \n",
      " conv_2_lrelu (LeakyReLU)    (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " conv_2_bn (BatchNormalizat  (None, 16, 21, 64)        256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_2_dropout (Dropout)    (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " conv_1_conv (Conv2D)        (None, 16, 21, 128)       73856     \n",
      "                                                                 \n",
      " conv_1_lrelu (LeakyReLU)    (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " conv_1_bn (BatchNormalizat  (None, 16, 21, 128)       512       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_1_dropout (Dropout)    (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " conv_0_conv (Conv2D)        (None, 16, 21, 256)       295168    \n",
      "                                                                 \n",
      " conv_0_lrelu (LeakyReLU)    (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " conv_0_bn (BatchNormalizat  (None, 16, 21, 256)       1024      \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " conv_0_dropout (Dropout)    (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " conv_00_conv (Conv2D)       (None, 16, 21, 512)       1180160   \n",
      "                                                                 \n",
      " conv_00_lrelu (LeakyReLU)   (None, 16, 21, 512)       0         \n",
      "                                                                 \n",
      " conv_00_bn (BatchNormaliza  (None, 16, 21, 512)       2048      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " conv_00_dropout (Dropout)   (None, 16, 21, 512)       0         \n",
      "                                                                 \n",
      " deconv_00_deconv (Conv2DTr  (None, 16, 21, 512)       2359808   \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " deconv_00_lrelu (LeakyReLU  (None, 16, 21, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " deconv_00_bn (BatchNormali  (None, 16, 21, 512)       2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " deconv_00_dropout (Dropout  (None, 16, 21, 512)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " deconv_0_deconv (Conv2DTra  (None, 16, 21, 256)       1179904   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_0_lrelu (LeakyReLU)  (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " deconv_0_bn (BatchNormaliz  (None, 16, 21, 256)       1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_0_dropout (Dropout)  (None, 16, 21, 256)       0         \n",
      "                                                                 \n",
      " deconv_1_deconv (Conv2DTra  (None, 16, 21, 128)       295040    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_1_lrelu (LeakyReLU)  (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " deconv_1_bn (BatchNormaliz  (None, 16, 21, 128)       512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_1_dropout (Dropout)  (None, 16, 21, 128)       0         \n",
      "                                                                 \n",
      " deconv_2_deconv (Conv2DTra  (None, 16, 21, 64)        73792     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_2_lrelu (LeakyReLU)  (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " deconv_2_bn (BatchNormaliz  (None, 16, 21, 64)        256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_2_dropout (Dropout)  (None, 16, 21, 64)        0         \n",
      "                                                                 \n",
      " deconv_3_deconv (Conv2DTra  (None, 16, 21, 32)        18464     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_3_lrelu (LeakyReLU)  (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " deconv_3_bn (BatchNormaliz  (None, 16, 21, 32)        128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_3_dropout (Dropout)  (None, 16, 21, 32)        0         \n",
      "                                                                 \n",
      " deconv_4_deconv (Conv2DTra  (None, 80, 105, 16)       18448     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " deconv_4_lrelu (LeakyReLU)  (None, 80, 105, 16)       0         \n",
      "                                                                 \n",
      " deconv_4_bn (BatchNormaliz  (None, 80, 105, 16)       64        \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " deconv_4_dropout (Dropout)  (None, 80, 105, 16)       0         \n",
      "                                                                 \n",
      " final_deconv (Conv2DTransp  (None, 160, 210, 1)       145       \n",
      " ose)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5526145 (21.08 MB)\n",
      "Trainable params: 5522113 (21.07 MB)\n",
      "Non-trainable params: 4032 (15.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a59cbe-8674-41b4-bcc8-1457b70f35e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"wGAN_discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " discriminator_input (Input  [(None, 160, 210, 1)]     0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " conv1_conv (Conv2D)         (None, 80, 105, 128)      1280      \n",
      "                                                                 \n",
      " conv1_lrelu (LeakyReLU)     (None, 80, 105, 128)      0         \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizati  (None, 80, 105, 128)      512       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv3_conv (Conv2D)         (None, 80, 105, 256)      295168    \n",
      "                                                                 \n",
      " conv3_lrelu (LeakyReLU)     (None, 80, 105, 256)      0         \n",
      "                                                                 \n",
      " conv3_bn (BatchNormalizati  (None, 80, 105, 256)      1024      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv5_conv (Conv2D)         (None, 80, 105, 512)      1180160   \n",
      "                                                                 \n",
      " conv5_lrelu (LeakyReLU)     (None, 80, 105, 512)      0         \n",
      "                                                                 \n",
      " conv5_bn (BatchNormalizati  (None, 80, 105, 512)      2048      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 40, 52, 512)       0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " final_conv (Conv2D)         (None, 40, 52, 1)         4609      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1484801 (5.66 MB)\n",
      "Trainable params: 1483009 (5.66 MB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2665514a-6201-4e22-8ea4-00ade02a4b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_downscaled_data(generator, coarse_data, fine_data, fine_nan_mask, num_members=10):\n",
    "    downscaled_data_list = []\n",
    "    \n",
    "    for _ in range(num_members):\n",
    "        # Generate noise\n",
    "        # noise_factor = 10\n",
    "        # noisy_coarse_data = coarse_data + noise_factor * tf.random.normal(shape=coarse_data.shape, mean=0.2, stddev=0.05)\n",
    "        # noisy_coarse_data = xr.where(noisy_coarse_data<0, 0.0, noisy_coarse_data)\n",
    "        \n",
    "        # Generate predictions\n",
    "        downscaled_data = generator.predict(coarse_data.values.reshape(coarse_data.shape + (1,)), batch_size=32)\n",
    "        # downscaled_data = generator.predict(noisy_coarse_data.values.reshape(noisy_coarse_data.shape + (1,)), batch_size=32)\n",
    "        \n",
    "        # Create DataArray with proper attributes\n",
    "        downscaled_data_da = xr.DataArray(\n",
    "            name='precipitation', \n",
    "            data=downscaled_data.squeeze(), \n",
    "            dims=fine_data.dims, \n",
    "            coords=fine_data.coords, \n",
    "            attrs=fine_data.attrs\n",
    "        )\n",
    "        \n",
    "        # Apply NaN mask\n",
    "        downscaled_data_da = downscaled_data_da.where(~fine_nan_mask, np.nan)\n",
    "        \n",
    "        downscaled_data_list.append(downscaled_data_da)\n",
    "        del downscaled_data_da\n",
    "    \n",
    "    # Concatenate along the 'number' dimension\n",
    "    downscaled_data = xr.concat(downscaled_data_list, dim='number')\n",
    "    downscaled_data = downscaled_data.assign_coords(number=np.arange(len(downscaled_data_list)))\n",
    "    downscaled_data = downscaled_data.transpose('time', 'lat', 'lon', 'number')\n",
    "    del downscaled_data_list\n",
    "    \n",
    "    return downscaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db19a3e8-74bb-48b7-ac57-6112c82d123d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 15:47:43.035267: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape ingenerator/conv_4_dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-08-29 15:47:43.419025: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-29 15:47:43.422535: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-29 15:47:43.432304: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-29 15:47:43.441747: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-08-29 15:47:43.680905: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-08-29 15:47:44.879810: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 18s 34ms/step\n",
      "263/263 [==============================] - 3s 11ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 3s 12ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 2s 6ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 2s 8ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 2s 8ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "263/263 [==============================] - 4s 13ms/step\n",
      "CPU times: user 2min 52s, sys: 51.3 s, total: 3min 44s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "downscaled_data = generate_downscaled_data(generator, coarse_data, fine_data, fine_nan_mask, num_members=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3fdf8b-45b6-4613-8f63-a1e7fb601b04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "diro = '/work/bb0983/athul_satheesh/downscaled_data/europe/downscaled_data/'\n",
    "downscaled_data.to_netcdf(f'{diro}e_obs_eu_downscaled_wgan_prob_extended_eu_{epoch}epochs_adamV5.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "783fb070-d4d6-405d-993d-dd5f2adc5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_data = fine_data.where(~fine_nan_mask, np.nan)\n",
    "# coarse_data = coarse_data.where(~coarse_nan_mask, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e15b82-6783-4b26-a1bf-2540f34231dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE1 : 1.1187\n",
      "MAE5: 1.1193\n",
      "MAE10: 1.1182\n"
     ]
    }
   ],
   "source": [
    "# print(f\"CRPS : {np.nanmean(xs.crps_ensemble(observations=fine_data, forecasts=downscaled_data, member_dim='number') ):.4f}\")\n",
    "print(f\"MAE1 : {np.nanmean(abs(fine_data - downscaled_data.sel(number=0)) ):.4f}\")\n",
    "print(f\"MAE5: {np.nanmean(abs(fine_data - downscaled_data.sel(number=5)) ):.4f}\")\n",
    "print(f\"MAE10: {np.nanmean(abs(fine_data - downscaled_data.sel(number=10)) ):.4f}\")\n",
    "print(f\"MAE  : {np.nanmean(abs(fine_data - downscaled_data.mean('number')) ):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40165603-203a-4bfe-a088-df413420281c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# date1 = '2014-06-09' #'2021-06-15'\n",
    "# date2 = '2014-06-09' #'2021-09-15'\n",
    "\n",
    "# crps_data = xs.crps_ensemble(observations=fine_data.sel(time=slice(date1, date2)), \n",
    "#                              forecasts=downscaled_data.sel(time=slice(date1, date2)),\n",
    "#                             member_dim='number', dim='time')\n",
    "# # Convert to xarray DataArray if necessary\n",
    "# crps_data = xr.DataArray(crps_data, dims=[\"lat\", \"lon\"], coords={\"lat\": fine_data.lat, \n",
    "#                                                                          \"lon\": fine_data.lon,\n",
    "#                                                                         })\n",
    "\n",
    "# # Define the colormap colors\n",
    "# colors_blues2black = [(0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "# colors_RdBlBu = [(1, 0, 0), (0, 0, 0), (0, 0.90, 1)]  # Blue to Black\n",
    "\n",
    "# # Create the colormap\n",
    "# cmap_name = 'BluesToBlack'\n",
    "# blues_to_black = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors_blues2black)\n",
    "# Rd_bl_Bu = mcolors.LinearSegmentedColormap.from_list('RdBlBu', colors_RdBlBu)\n",
    "\n",
    "\n",
    "# fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12,10), sharex=True, sharey=True,\n",
    "#                         subplot_kw=dict(projection=ccrs.PlateCarree(), facecolor='black'),\n",
    "#                         gridspec_kw={'wspace': -0.05, 'hspace': -0.45})\n",
    "\n",
    "# # Define the plots list\n",
    "# plots = [coarse_data, fine_data, downscaled_data.mean(dim='number'), crps_data]\n",
    "# # cmap = [blues_to_black, blues_to_black, blues_to_black, 'afmhot']\n",
    "# cmap = ['turbo', 'turbo', 'turbo', 'afmhot']\n",
    "# levels = [np.arange(0,20.125,0.125), np.arange(0,20.125,0.125), np.arange(0,20.125,0.125), np.arange(0,10.125,0.125)]\n",
    "# title = ['a) Coarse','b) Fine','c) Downscaled ENS mean','d) CRPS']\n",
    "# ticks = [np.arange(0,24,4), np.arange(0,24,4), np.arange(0,24,4), np.arange(0,12,2)]\n",
    "\n",
    "# for i, ax in enumerate(axs.flatten()):\n",
    "#     if i != (len(plots) - 1):\n",
    "#         plots[i].sel(time=slice(date1, date2)).mean('time').plot(cmap=cmap[i], levels=levels[i], \n",
    "#                                                                  ax=ax, cbar_kwargs={'orientation':'vertical',\n",
    "#                                                                                     'pad':0.01, 'label':'',\n",
    "#                                                                                     'shrink':0.48, 'drawedges':False,\n",
    "#                                                                                     'ticks': ticks[i], },\n",
    "#                                                                  alpha=0.75)\n",
    "#     else:\n",
    "#         plots[-1].plot(cmap=cmap[i], levels=levels[i], \n",
    "#                        ax=ax, cbar_kwargs={'orientation':'vertical',\n",
    "#                                            'pad':0.01, 'label':'',\n",
    "#                                            'shrink':0.48, 'drawedges':False,\n",
    "#                                            'ticks': ticks[i], },\n",
    "#                        alpha=0.90)\n",
    "    \n",
    "#     ax.text(0, 55.2, f'{title[i]}', size=13, color='white')\n",
    "#     ax.coastlines(linewidth=1.5, color='white')\n",
    "#     ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=1.5, edgecolor='white')\n",
    "#     ax.patch.set_facecolor('black')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
